{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "import warnings\n",
    "\n",
    "# Initialize tools\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Do this: pip install google-cloud-bigquery-storage and db_dtypes\n",
    "# Suppress warnings with a specific message\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"Your application has authenticated using end user credentials from Google Cloud SDK without a quota project.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model_name=\"gemini-2.0-flash\", temperature=0.4, top_k=30, top_p=0.3):\n",
    "    ai_client = GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=temperature,  \n",
    "            top_k=top_k,  \n",
    "            top_p=top_p\n",
    "        )\n",
    "    )\n",
    "    response_result = ai_client.generate_content(prompt)\n",
    "    return response_result.candidates[0].content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "project_name = \"snowplow-cto-office\"\n",
    "bigquery_client = bigquery.Client(project=project_name)\n",
    "product = \"smartbill\"\n",
    "app_id = \"smartbill\"\n",
    "#product = \"vnet_autopay\"\n",
    "#product = \"eplus\"\n",
    "dataset_id = f\"\"\"snowplow-cto-office.snowplow_{product}\"\"\"\n",
    "#full_responses_table_name = f\"\"\"snowplow-cto-office.snowplow_{product}.Vismanet_AutoPay_events_filtered_L60D\"\"\"\n",
    "\n",
    "table_names = [f\"{app_id}_simple_urlpath_sequences\", f\"{app_id}_events_custom_T60D\", f\"{app_id}_page_views_aggregated\", f\"{app_id}_session_chunks\", f\"{app_id}_simple_title_sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_responses_table_name = f\"\"\"{dataset_id}.{app_id}_session_chunks\"\"\"\n",
    "#Vismanet_AutoPay_events_filtered_L60D\n",
    "query_headers = f\"\"\"SELECT\n",
    "        column_name AS field_name,\n",
    "        data_type AS field_type,\n",
    "        description AS field_description,\n",
    "    FROM\n",
    "        `{dataset_id}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "    WHERE\n",
    "        table_name = '{app_id}_session_chunks';\n",
    "    \"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query_headers)\n",
    "table = query_job.result()\n",
    "\n",
    "rows = list(table)\n",
    "\n",
    "all_fields_type = {row[0]: row[1] for row in rows}\n",
    "all_fields_desc = {row[0]: row[2] for row in rows}\n",
    "all_fields_names = {row[0]: row[0] for row in rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = {}\n",
    "for i in table_names:\n",
    "    query_tables_summary = f\"\"\"SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `{dataset_id}.INFORMATION_SCHEMA.TABLE_OPTIONS`\n",
    "    WHERE\n",
    "        option_name = 'description'\n",
    "        AND table_name = '{i}';\n",
    "    \"\"\"\n",
    "    query_job = bigquery_client.query(query_tables_summary)\n",
    "    table = query_job.result()\n",
    "    rows = list(table)\n",
    "    summary_list[f\"{i}\"] = rows[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_selection(bigquery_client, prompt, keywords, assumptions = None):\n",
    "    print(\"Bigquery start.\")\n",
    "    #query_job = bigquery_client.query(query_headers)\n",
    "    #table = query_job.result()\n",
    "    # headers_values = []\n",
    "    #for row in table:\n",
    "    #    headers_values.append(row[:])\n",
    "    text_with_headers = f\"\"\"\n",
    "\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Assumptions about prompt:**\n",
    "    - {assumptions}\n",
    "\n",
    "    **Table schema:**\n",
    "    - Name of fields: {all_fields_names}\n",
    "    - Data type of values in the fields: {all_fields_type}\n",
    "    - Field descriptions: {all_fields_desc}\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Identify and list all relevant fields from the table schema that are useful for answering the prompt.\n",
    "    2. Use these keywords to find the relevant fields: {keywords}.\n",
    "    3. Do not include any extraneous symbols, such as JSON formatting, brackets, or custom fields.\n",
    "    4. For each selected field, explain its relevance and how it helps to answer the prompt.\n",
    "    5. Make use of assumptions if they exist. The assumptions are correct and is incorporated into the prompt.\n",
    "\n",
    "    **Important:**\n",
    "    - If **all necessary fields** to answer the prompt are present in the schema, proceed to list the fields and their corresponding use cases: field_name, [use case]\n",
    "    - If the prompt mentions a clearly defined concept or event that is missing AND cannot be calculated or derived from the available data, return only: `False, [explanation]`\n",
    "    - Do **not** make assumptions or workarounds unless explicitly allowed.\n",
    "    - ABSOLUTELY DO NOT USE ANY CUSTOME FIELDS. CUSTOM FIELDS ARE NOT ALLOWED.\n",
    "\n",
    "    Output format:\n",
    "    field_name1, use case\n",
    "    field_name2, use case\n",
    "    ...\n",
    "\n",
    "    Do **not** hallucinate or infer information.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Bigquery end.\")\n",
    "    fields_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.05, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    print(fields_response)\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    lines = fields_response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    var_type = []\n",
    "\n",
    "\n",
    "    for line in lines:\n",
    "        if \",\" in line:\n",
    "            first, second = line.split(\",\", 1) \n",
    "            first_part.append(first.strip())  \n",
    "            second_part.append(second.strip())  \n",
    "\n",
    "    for i in first_part:\n",
    "        var_type.append(all_fields_type[i])\n",
    "\n",
    "    fields_type = {\n",
    "        first_part[i]: {\n",
    "            'data_type': var_type[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    fields_desc = {\n",
    "        first_part[i]: {\n",
    "            'description': second_part[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    return fields_type, fields_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sql_error(prompt, keywords, expected_result, sql_code, error, fields_type, fields_desc, strategy):\n",
    "    final_prompt = f\"\"\"\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Important keywords:**\n",
    "    - {keywords}\n",
    "\n",
    "    **Strategy for creating SQL code:**\n",
    "    - {strategy}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected_result}\n",
    "    \n",
    "    ### **Original SQL Query (Faulty):**\n",
    "    {sql_code}\n",
    "\n",
    "    ### **Error Message:** \n",
    "    {error}\n",
    "\n",
    "    ### **Table Details:** \n",
    "    - Table name: {full_responses_table_name}\n",
    "    - Field data types: {fields_type}\n",
    "    - Field descriptions: {fields_desc}\n",
    "\n",
    "    ### **Task:** \n",
    "    - Review the query and update the query to solve the error while adhering to the prompt, keywords, strategy, and expected result:\n",
    "    \n",
    "    ### **Guidelines:** \n",
    "    - Look at the error and identify where in the code the error exists.\n",
    "    - Look at the numbers [xx, xx]\n",
    "    - Resolve the issue by identifying and changing the code appropriately.\n",
    "\n",
    "    ### **Output:**  \n",
    "    Please provide only the corrected SQL query. Ensure the corrected query is syntactically and logically sound, and adheres to the provided guidelines and constraints.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.1, \n",
    "        top_k=40, \n",
    "        top_p=0.3\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    return response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(prompt, fields_type, fields_desc, query, expected_result, assumptions, strategy):\n",
    "    final_prompt = f\"\"\"\n",
    "    ### **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    ### **Assumptions:** \n",
    "    {assumptions}\n",
    "\n",
    "    ### **Strategy for creating SQL code:** \n",
    "    {strategy}\n",
    "\n",
    "    ### **SQL Query:** \n",
    "    {query}\n",
    "\n",
    "    ### **Expected result:** \n",
    "    {expected_result}\n",
    "\n",
    "    ### **Table schema:** \n",
    "    - Fields descriptions: {fields_desc}\n",
    "    - Fields type: {fields_type}\n",
    "\n",
    "    ### **Task:**  \n",
    "    - Does this query align with the combination of the prompt, the expected result?\n",
    "    - Will the syntax work for BigQuery?\n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - Assume the query is incorrect unless there is strong evidence it is correct.  \n",
    "    - If answering \"Yes,\" to a task, explicitly explain why.  \n",
    "    - If answering \"No,\" to a task, identify the issue and explain why it does not meet the requirement.  \n",
    "    - Look at the query and see if the code makes sense and produces reasonable result.\n",
    "    - Answer the task questions indepnedently from each other.\n",
    "    - Follow the output format.\n",
    "    \n",
    "    ### **Output format:**  \n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.1, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    lines = response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    for line in lines:\n",
    "        if \".\" in line:  # Ensure there is a comma before splitting\n",
    "            first, second = line.split(\".\", 1)  # Split only at the first comma\n",
    "            first_part.append(first.strip())  # Store the first part (column name)\n",
    "            second_part.append(second.strip())  # Store the second part (description)\n",
    "\n",
    "    check_list = []\n",
    "    for i in range(len(first_part)):\n",
    "        if first_part[i] == \"No\":\n",
    "            check_list.append(second_part[i])\n",
    "\n",
    "    return check_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_interpretation(prompt, result, code):\n",
    "    result_text = f\"\"\"\n",
    "    ### **Prompt:**\n",
    "    {prompt}  \n",
    "\n",
    "    ### **SQL code:**   \n",
    "    {code}  \n",
    "\n",
    "    ### **Data:**   \n",
    "    {result}  \n",
    "\n",
    "\n",
    "    ### **Task:**  \n",
    "    Analyze the provided dataset and generate a meaningful interpretation that answers the given prompt in a user-friendly manner.  \n",
    "\n",
    "    ### **Steps:**  \n",
    "    1. **Answer the question directly.** Provide a clear, data-driven response.  \n",
    "    2. **Extract key insights.** Identify trends, anomalies, or correlations that are not immediately obvious.  \n",
    "    3. **Use external knowledge when relevant.** If applicable, explain insights using common patterns or domain knowledge.  \n",
    "    4. **Focus on the overall pattern** rather than unnecessary details unless a specific outlier is crucial.  \n",
    "    5. **State relevant assumptions.** Only include assumptions that impact the interpretation of result (avoid discussing column names, data types, or table structures).  \n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - **Be concise.** Prioritize clarity over lengthy explanations.  \n",
    "    - **Use a structured format.** Keep responses readable with bullet points and section headings.  \n",
    "    - **Avoid redundant details.** Don’t restate information that is already evident from the dataset.  \n",
    "    - **Ignore missing table schema details.** Focus on strategy, definitions, and calculations instead.  \n",
    "    - **Assistant with a friendly tone.** Speak to the user as if this is the data you have to asnwer the prompt. Make objective statements and discuss uncertainties when possible.  \n",
    "    - **BigQuery.** The data is extracted from BigQuery with (U.S weekday numbering convention e.g. Sunday is 1 and Monday is 2).\n",
    "    - **Use the code for interpretation** The SQL code that extracts the data contains information which explains certain assumptions and why the data looks the way it does. Make use of the code when making assumptions.\n",
    "\n",
    "    ### **Expected Output Format:**  \n",
    "    1. **Best Answer to the Prompt** (direct response)  \n",
    "    2. **Key Insights & Trends** (summary of findings)  \n",
    "    3. **Relevant Assumptions** (only those impacting interpretation of the result)  \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    final_answer_response = generate_response(\n",
    "        result_text, \n",
    "        temperature=0.3,  # More creativity\n",
    "        top_k=40, \n",
    "        top_p=0.6\n",
    "    )\n",
    "\n",
    "    return final_answer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(prompt, assumptions = None):\n",
    "    final_prompt = f\"\"\"\n",
    "\n",
    "    **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    {assumptions}\n",
    "\n",
    "    **Guidelines:** \n",
    "    - Extract the most important keywords from the prompt. \n",
    "    - The keywords will be given to a LLM together with the prompt so that it can better understand the prompt and what need to be answered.\n",
    "    - Choose relevant words in the prompt that need to be considered rather that conjuring up new ones. Do not include redundant keywords.\n",
    "    - Make use of assumptions if they exist. The assumptions are correct and are meant to clarify any ambiguous word or concept. You can think of them as addition to the prompt.\n",
    "\n",
    "    ** Output format:** \n",
    "    <[keyword1, keyword2, ...]>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    keywords = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2, \n",
    "            top_k=20, \n",
    "            top_p=0.5\n",
    "        )\n",
    "\n",
    "    print(keywords)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected(prompt, fields_type, fields_desc, assumptions = None):\n",
    "    final_prompt = f\"\"\"\n",
    "    ### **Task:**   \n",
    "    You are retrieving data from BigQuery to answer user queries. Given a prompt, state the expected result that the LLM should provide.  \n",
    "\n",
    "    ### **Prompt:**   \n",
    "    {prompt} \n",
    "\n",
    "    ### **Assumptions:**\n",
    "    {assumptions}\n",
    "\n",
    "    ### **Available table schema:**\n",
    "    - Fields description: {fields_desc}\n",
    "    - Fields type: {fields_type}\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Use available data information from the fields to create the best possible expected result for the prompt.\n",
    "    - Only state what the expected result should be with no explanations about it.\n",
    "    - The expected result should reflect what the LLM should output after querying BigQuery. In essence, how the format and structure of the data should look like. \n",
    "    - Let the output be in concise sentences.\n",
    "    - Make use of the assumptions when creating the expected result. However, only take the most reasonable parts that are relevant.\n",
    "\n",
    "    **Output format:**  \n",
    "    Expected result: <Your response here>\n",
    "    \"\"\"\n",
    "    \n",
    "    response = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2,  # Ensures consistency\n",
    "            top_k=20, \n",
    "            top_p=0.5\n",
    "        )\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_code(prompt, fields_type, fields_desc, strategy, keywords, expected_result, assumptions = None):\n",
    "    text_with_headers = f\"\"\"\"\n",
    "    **Prompt:** {prompt}\n",
    "\n",
    "    **Table schema:** \n",
    "    - Data types: {fields_type} \n",
    "    - Descriptions: {fields_desc} \n",
    "    - Table: {full_responses_table_name}\n",
    "\n",
    "    **Strategy:**\n",
    "    - {strategy} \n",
    "\n",
    "    **Keywords:** \n",
    "    - {keywords}\n",
    "\n",
    "    **Expected result:** \n",
    "    - {expected_result}\n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    - {assumptions}\n",
    "\n",
    "    **Constraints:** \n",
    "    - The query is sent to BigQuery. It needs to follow BigQuery syntax.\n",
    "    - Fully follow the strategy\n",
    "    - Fully create a query that aligns with the expected result\n",
    "    - Keep query costs as low as possible\n",
    "\n",
    "    ### **Task:**  \n",
    "    - Generate the best possible BigQuery SQL query that:  \n",
    "    1. Follows the strategy step-by-step without deviation. Treat the strategy as a strict blueprint; implement each step exactly as described.\n",
    "    2. Exclude all Null Values from everywhere (`IS NOT NULL`)\n",
    "\n",
    "    **Query Guidelines:**\n",
    "    - Select only necessary fields; avoid extra data.\n",
    "    - Use accurate column names; no transformations.\n",
    "    - Prefer partition filtering over `EXTRACT()`. Use `DATE_TRUNC(date_column, DATE_PART)` correctly (e.g., `DATE_TRUNC(session_started_date, WEEK)`), without string literals.\n",
    "    - Use approximate counts where possible.\n",
    "    - Consider clustering for better filtering.\n",
    "    - **Exclude NULL values** (`IS NOT NULL`).\n",
    "    - Make use of the assumptions. The assumptions are correct and is incorporated into the prompt.\n",
    "    - Order and keep the data user-friendly and answers the prompt.\n",
    "    - Be careful of LIMIT expects an integer literal or parameter\n",
    "    - The query should only give the user ONE table of result.\n",
    "\n",
    "    Use standard SQL. The query will be sent to **BigQuery**, so DO NOT INCLUDE EXPLANATIONS. Make sure the query is VALID. Do not hallucinate.\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.1, \n",
    "        top_k=20, \n",
    "        top_p=0.2\n",
    "    )\n",
    "\n",
    "    return sql_query_response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiAgent = DataQueryAgent(project_name, bigquery_client, generate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"Where are most of our users from? we don't have information on country\"\n",
    "#prompt = \"Which companies have the highest engagement?\"\n",
    "#prompt = \"Which customers have the most sessions?\"\n",
    "prompt = \"Based on the bigger customers; what days and times is the best for performing updates, maintenance?\"\n",
    "#prompt = \"At what times and days are people starting sessions the least?\"\n",
    "#prompt = \"Based on the bigger customers; what days and times do least sessions start?\"\n",
    "#prompt = \"Based on the top 10 customers with the most users; what days and times are the best for performing updates, maintenance?\"\n",
    "#prompt = \"How do system outages impact user behavior? \"\n",
    "#prompt = \"How did the user behavior change between 30th december 2024, 31th december 2024, 1th january 2025 and 2nd january 2025? \"\n",
    "prompt = \"How did the user behavior change between 2024 and 2025 for the months?\"\n",
    "#prompt = \"Do performance issues correlate with a drop in activity?\"\n",
    "#prompt = \"What combinations of browser and os are the worst according to performance?\"\n",
    "#prompt = \"Based on user behavior, what will the peak activity hours be tomorrow?\"\n",
    "#prompt = \"How many users used each product throughout january 2025?\"\n",
    "#prompt = \"How does app performance affect user engagement and retention?\"\n",
    "#prompt = \"Which devices or OS versions are experiencing the worst performance (slower load times, etc)? and total page load time\"\n",
    "#prompt = \"Which devices and OS versions are experiencing the worst performance?\"\n",
    "#prompt = \"Vilka OS system och enheter är sämst enligt performance?\"\n",
    "#prompt = \"Can you see a pattern if you compare Network Latency, Page Load Fails, Page Loading Time and Device and browsers?\"\n",
    "#prompt = \"for all windows user, which brare best based on performance? Give top 20\"\n",
    "#prompt = \"for all windows user, is edge or chrome better for performance? Compare all versions of edge and chrome. also show number of occurences of the combinations\"\n",
    "#prompt = \"for all windows user, is edge or chrome better for performance? filter out and look for browsers that contain the name either edge or chrome. Compare all versions.\" \n",
    "#prompt = \"Can you calculate the DAU/WAU and WAU/MAU stickiness for the products for all months in 2024?\"\n",
    "#prompt = \"Can you calculate the monthly stickiness for the products in 2024?\"\n",
    "#prompt = \"Can you calculate the WAU/MAU stickiness for the products for all weeks in 2024?\"\n",
    "#prompt = \"Calculate the weekly stickiness (defined as the percentage of weekly active users who used the product in the previous week) for each product in our catalog for every week of the year 2024. Provide the output as a table with the following columns: Week Number (2024), Product name, and Weekly Stickiness (%)?\"\n",
    "#prompt = \"Are there any insights in the correlation between the size of cutsomers and have huge page load times?\"\n",
    "#prompt = \"What are the network latency & slow load times observed during hours when users are most active\"\n",
    "#prompt = \"Most common drop-off points\"\n",
    "prompt = \"How much did the total session time increase or decrease in percentage and number between each month in 2025 compared to the months in 2024? Can you divide into user roles\"\n",
    "#prompt = \"For all Windows users, is Edge or Chrome better according to performance? Look for browsers that contain the name either edge or chrome. Compare all versions.\"\n",
    "#prompt = \"What devices are mostly used? and what dimensions are they?\"\n",
    "#prompt = \"For all Windows users, is Edge or Chrome better according to performance? Look for browsers that contain the name either edge or chrome. Compare all versions.\"\n",
    "#prompt = \"For all Windows users, is Edge or Chrome better according to performance? Look for browsers that contain the name either edge or chrome. Compare all versions of edge and chrome.\"\n",
    "#USers from vestlandfylke has ued teh solution\n",
    "#prompt = \"Can you calculate the WAU/MAU stickiness for the products for all weeks in 2024?\"\n",
    "#prompt = \"for all windows user, is edge or chrome better for performance? Compare all versions of edge and chrome.\"\n",
    "\n",
    "response = aiAgent.process_prompt(prompt)\n",
    "print(response)\n",
    "#new_user_input = input(\"Ask your follow-up question\")\n",
    "#response = aiAgent.process_prompt(new_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQueryAgent:\n",
    "    \"\"\"\n",
    "    A class responsible for processing user prompts to generate and validate SQL queries \n",
    "    using BigQuery, incorporating user clarifications and query refinement.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_id: str, bigquery_client, generate_response_fn):\n",
    "        self.client = bigquery_client\n",
    "        self.project_id = project_id\n",
    "        self.generate_response = generate_response_fn\n",
    "    \n",
    "    def process_prompt(self, user_input):\n",
    "        \"\"\"Processes user input to generate, validate, and execute an SQL query.\"\"\"\n",
    "        \n",
    "        # Extract initial query parameters\n",
    "        keywords = extract_keywords(user_input)\n",
    "        fields_type, fields_desc = field_selection(self.client, user_input, keywords)\n",
    "\n",
    "        # Handle assumptions\n",
    "        assumptions = self.make_assumptions(user_input, fields_type, fields_desc, keywords)\n",
    "        assumptions = self.refine_assumptions(user_input, assumptions)\n",
    "        print(assumptions)\n",
    "        \n",
    "        # Re-evaluate query parameters\n",
    "        #user_input = self.update_prompt(user_input, keywords, assumptions)\n",
    "        #print(\"Updated prompt: \" + user_input)\n",
    "        keywords = extract_keywords(user_input, assumptions)\n",
    "        fields_type, fields_desc = field_selection(self.client, user_input, keywords, assumptions)\n",
    "\n",
    "        expected_result = expected(user_input, fields_type, fields_desc, assumptions)\n",
    "\n",
    "        #user_input = self.update_prompt(user_input, keywords, expected_result, assumptions)\n",
    "        #print(\"Updated prompt: \" + user_input)\n",
    "        \n",
    "        # Generate and validate SQL query\n",
    "        sql_code, strategy = self.generate_valid_sql(user_input, fields_type, fields_desc, keywords, expected_result, assumptions)\n",
    "        if not sql_code:\n",
    "            return \"Failed to generate a valid SQL query after 3 attempts.\"\n",
    "        \n",
    "        # Validate SQL query using BigQuery dry run\n",
    "        valid_result, result_df = self.validate_sql_query(prompt, keywords, expected_result, sql_code, fields_type, fields_desc, strategy)\n",
    "        if not valid_result:\n",
    "            return \"An error occurred. Please try again.\"\n",
    "        \n",
    "        # Process query results\n",
    "        result_df = self.clean_results(result_df)\n",
    "        interpretation = result_interpretation(user_input, result_df, sql_code)\n",
    "        print(result_df.to_string())\n",
    "        print(result_df)\n",
    "        return interpretation\n",
    "    \n",
    "    def refine_assumptions(self, user_input, assumptions):\n",
    "        \"\"\"Asks the user to confirm or refine assumptions.\"\"\"\n",
    "        while True:\n",
    "            user_clarifications = input(self.clarify_assumptions(assumptions))\n",
    "            if user_clarifications.lower() in {\"\", \"yes\", \"y\"}:\n",
    "                return assumptions\n",
    "            assumptions = self.interpret_clarification(user_input, assumptions, user_clarifications)\n",
    "    \n",
    "    def generate_valid_sql(self, user_input, fields_type, fields_desc, keywords, expected_result, assumptions):\n",
    "        \"\"\"Attempts to generate a valid SQL query within a loop.\"\"\"\n",
    "        \n",
    "        for attempt in range(3):\n",
    "            strategy = self.aggregation_strategy(user_input, fields_type, fields_desc, keywords, expected_result, assumptions)\n",
    "            print(strategy)\n",
    "            sql_code = create_sql_code(user_input, fields_type, fields_desc, strategy, keywords, expected_result, assumptions)\n",
    "            print(\"----------------------------------------------------------------------------------\")\n",
    "            print(attempt)\n",
    "            print(sql_code)\n",
    "            validation_errors = verify(user_input, fields_type, fields_desc, sql_code, expected_result, assumptions, strategy)\n",
    "            if not validation_errors:\n",
    "                return sql_code, strategy  # Return valid SQL\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "    def validate_sql_query(self, prompt, keywords, expected, sql_code, fields_type, fields_desc, strategy):\n",
    "        \"\"\"Performs a dry run of the SQL query to check validity.\"\"\"\n",
    "        job_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "        \n",
    "        for attempt in range(3):\n",
    "            print(\"----------------------------------------------------------------------------------\")\n",
    "            print(attempt + 10)\n",
    "            try:\n",
    "                query_job = self.client.query(sql_code, job_config=job_config)\n",
    "                query_job.result()\n",
    "                print(f\"Query is valid. Estimated processing: {query_job.total_bytes_processed / 1e9:.2f} GB.\")\n",
    "                return True, self.client.query(sql_code).to_dataframe()\n",
    "            except Exception as e:\n",
    "                print(f\"Query validation failed (Attempt {attempt + 1}/3): {e}\")\n",
    "                sql_code = correct_sql_error(prompt, keywords, expected, sql_code, e, fields_type, fields_desc, strategy)\n",
    "                #sql_changes = correct_sql_error(prompt, expected, sql_code, e, fields_type, fields_desc)\n",
    "                #sql_code = correct_sql_error2(prompt, keywords, expected, sql_code, e, fields_type, fields_desc, strategy, sql_changes)\n",
    "        return False, None\n",
    "    \n",
    "    def clean_results(self, result_df):\n",
    "        \"\"\"Cleans up missing or empty values in the query results.\"\"\"\n",
    "        return result_df.map(lambda x: \"Missing Data\" if x in {\"\", \"None\"} else x).dropna()\n",
    "    \n",
    "    def clarify_assumptions(self, assumptions):\n",
    "        return f\"Are the following assumptions correct?\\n\\n{assumptions}\"\n",
    "    \n",
    "    def interpret_clarification(self, prompt, assumptions, user_clarifications):\n",
    "        clarification_prompt = f\"\"\"\n",
    "        ### **Initial Prompt:** {prompt}\n",
    "        ### **Current Assumptions:** {assumptions}\n",
    "        ### **User Clarifications:** {user_clarifications}\n",
    "        ### **Task:**\n",
    "        - Update assumptions based on clarifications.\n",
    "        - If no change is needed, return the current assumptions.\n",
    "        \"\"\"\n",
    "        return self.generate_response(clarification_prompt, temperature=0.2, top_k=40, top_p=0.5)\n",
    "    \n",
    "    def make_assumptions(self, prompt, fields_type, fields_desc, keywords):\n",
    "        \"\"\"Generates initial assumptions based on input.\"\"\"\n",
    "        strategy_prompt = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "        ### **Table Info:**\n",
    "        - Fields Type: {fields_type}\n",
    "        - Fields Description: {fields_desc}\n",
    "        - Table name: {full_responses_table_name}\n",
    "        \n",
    "        ### **Constraints:**\n",
    "        - Use only given fields.\n",
    "        - No external data or assumptions beyond the provided fields.\n",
    "        \n",
    "        ### **Task:**\n",
    "        - Propose short, reasonable, and user-friendly assumptions to resolve potential ambiguities in the prompt, leveraging the table info implicitly.\n",
    "        - Propose reasonable definitions, calculations and other clarifications on the prompt.\n",
    "\n",
    "        ### **Guidelines:**\n",
    "        - Base assumptions on the most likely intent of the prompt, and keywords, informed by available data patterns from the table.\n",
    "        - Keep assumptions simple and verifiable by the user, who lacks table schema knowledge.\n",
    "        - Remember that the user cannot read all assumptions if they are too long. That is why it is important to keep each assumptions short as punctual.\n",
    "        - Output a numeric list.\n",
    "        - Do NOT generate SQL code.\n",
    "        \n",
    "        ### **Output Format:**\n",
    "        1. ...\n",
    "        2. ...\n",
    "        \"\"\"\n",
    "        return self.generate_response(strategy_prompt, temperature=0.1, top_k=20, top_p=0.3)\n",
    "    \n",
    "    def aggregation_strategy(self, prompt, fields_type, fields_desc, keywords, expected_result, assumptions):\n",
    "        strategy_prompt = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "        ### **Expected Result:** {expected_result}\n",
    "        ### **Table Details:**\n",
    "        - Fields Type: {fields_type}\n",
    "        - Fields Description: {fields_desc}\n",
    "        ### **Assumptions:**\n",
    "        - {assumptions}\n",
    "        ### **Constraints:** \n",
    "        - Use only the fields in the specified table—no external data or tables.  \n",
    "        - Base the strategy solely on the given prompt, keywords, expected result, and table details.  \n",
    "        ### **Task:** \n",
    "        - Suggest specific SQL operations in a step-by-step tailored to the prompt, assumptions and expected result.\n",
    "\n",
    "        ### **Guidelines:**\n",
    "        - Have many steps so that nothing is lost.\n",
    "        - Do not generate executable SQL.\n",
    "        - Keep the strategy concise and focused—no fluff or extraneous steps.\n",
    "        - Make sure to give steps to make the query as user friendly as possible.\n",
    "\n",
    "         ### **Output:**   \n",
    "        - **Step-by-Step Strategy:** (\"Title/Purpose\" - do this)  \n",
    "        \"\"\"\n",
    "\n",
    "        return self.generate_response(strategy_prompt, temperature=0.1, top_k=40, top_p=0.5)\n",
    "    \n",
    "    def update_prompt(self, prompt, keywords, assumptions):\n",
    "\n",
    "        strategy_prompt = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "\n",
    "        ### **Assumptions:**\n",
    "        - {assumptions}\n",
    "        ### **Task:** \n",
    "        - Update the prompt by considering the keywords, and assumptions.\n",
    "        - By update, you should update it so that it aligns with the keywords, and assumptions.\n",
    "        - Make it as short and concise as possible.\n",
    "        - Everything in the original prompt is still important and you need to conider what is said.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.generate_response(strategy_prompt, temperature=0.2, top_k=40, top_p=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
