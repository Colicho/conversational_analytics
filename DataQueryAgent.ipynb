{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "import warnings\n",
    "\n",
    "# Do this: pip install google-cloud-bigquery-storage and db_dtypes\n",
    "\n",
    "# Suppress warnings with a specific message\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"Your application has authenticated using end user credentials from Google Cloud SDK without a quota project.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model_name=\"gemini-2.0-flash\", temperature=0.4, top_k=30, top_p=0.3):\n",
    "    ai_client = GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=temperature,  \n",
    "            top_k=top_k,  \n",
    "            top_p=top_p\n",
    "        )\n",
    "    )\n",
    "    response_result = ai_client.generate_content(prompt)\n",
    "    return response_result.candidates[0].content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "project_name = \"placeholder\"\n",
    "bigquery_client = bigquery.Client(project=project_name)\n",
    "product = \"placeholder\"\n",
    "app_id = \"placeholder\"\n",
    "dataset_id = f\"\"\"snowplow-cto-office.snowplow_{product}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_responses_table_name = f\"\"\"{dataset_id}.{app_id}_session_chunks\"\"\"\n",
    "\n",
    "query_headers = f\"\"\"SELECT\n",
    "        column_name AS field_name,\n",
    "        data_type AS field_type,\n",
    "        description AS field_description,\n",
    "    FROM\n",
    "        `{dataset_id}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "    WHERE\n",
    "        table_name = '{app_id}_session_chunks';\n",
    "    \"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query_headers)\n",
    "table = query_job.result()\n",
    "\n",
    "rows = list(table)\n",
    "\n",
    "all_fields_type = {row[0]: row[1] for row in rows}\n",
    "all_fields_desc = {row[0]: row[2] for row in rows}\n",
    "all_fields_names = {row[0]: row[0] for row in rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(prompt, assumptions = None):\n",
    "    instructions = f\"\"\"\n",
    "\n",
    "    **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    {assumptions}\n",
    "\n",
    "    **Guidelines:** \n",
    "    - Extract the most important keywords from the prompt. \n",
    "    - The keywords will be given to a LLM together with the prompt so that it can better understand the prompt and what need to be answered.\n",
    "    - Choose relevant words in the prompt that need to be considered rather that conjuring up new ones. Do not include redundant keywords.\n",
    "    - Make use of assumptions if they exist. The assumptions are correct and are meant to clarify any ambiguous word or concept. You can think of them as addition to the prompt.\n",
    "\n",
    "    ** Output format:** \n",
    "    <[keyword1, keyword2, ...]>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    keywords = generate_response(instructions, temperature=0.2, top_k=20, op_p=0.5)\n",
    "    #print(keywords)\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_selection(prompt, keywords, assumptions = None):\n",
    "    instructions = f\"\"\"\n",
    "\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Assumptions about prompt:**\n",
    "    - {assumptions}\n",
    "\n",
    "    **Table schema:**\n",
    "    - Name of fields: {all_fields_names}\n",
    "    - Data type of values in the fields: {all_fields_type}\n",
    "    - Field descriptions: {all_fields_desc}\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Identify and list all relevant fields from the table schema that are useful for answering the prompt.\n",
    "    2. Use these keywords to find the relevant fields: {keywords}.\n",
    "    3. Do not include any extraneous symbols, such as JSON formatting, brackets, or custom fields.\n",
    "    4. For each selected field, explain its relevance and how it helps to answer the prompt.\n",
    "    5. Make use of assumptions if they exist. The assumptions are correct and is incorporated into the prompt.\n",
    "\n",
    "    **Important:**\n",
    "    - If **all necessary fields** to answer the prompt are present in the schema, proceed to list the fields and their corresponding use cases: field_name, [use case]\n",
    "    - If the prompt mentions a clearly defined concept or event that is missing AND cannot be calculated or derived from the available data, return only: `False, [explanation]`\n",
    "    - Do **not** make assumptions or workarounds unless explicitly allowed.\n",
    "    - ABSOLUTELY DO NOT USE ANY CUSTOM FIELDS. CUSTOM FIELDS ARE NOT ALLOWED.\n",
    "\n",
    "    Output format:\n",
    "    field_name1, use case\n",
    "    field_name2, use case\n",
    "    ...\n",
    "\n",
    "    Do **not** hallucinate or infer information.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fields_response = generate_response(instructions, temperature=0.05, top_k=30, top_p=0.3)\n",
    "\n",
    "    #print(fields_response)\n",
    "    #print(\"----------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    lines = fields_response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    var_type = []\n",
    "\n",
    "    for line in lines:\n",
    "        if \",\" in line:\n",
    "            first, second = line.split(\",\", 1) \n",
    "            first_part.append(first.strip())  \n",
    "            second_part.append(second.strip())  \n",
    "\n",
    "    for i in first_part:\n",
    "        var_type.append(all_fields_type[i])\n",
    "\n",
    "    fields_type = {\n",
    "        first_part[i]: {\n",
    "            'data_type': var_type[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    fields_desc = {\n",
    "        first_part[i]: {\n",
    "            'description': second_part[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    return fields_type, fields_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected(prompt, fields_type, fields_desc, assumptions = None):\n",
    "    instructions = f\"\"\"\n",
    "    ### **Task:**   \n",
    "    You are retrieving data from BigQuery to answer user queries. Given a prompt, state the expected result that the LLM should provide.  \n",
    "\n",
    "    ### **Prompt:**   \n",
    "    {prompt} \n",
    "\n",
    "    ### **Assumptions:**\n",
    "    {assumptions}\n",
    "\n",
    "    ### **Available table schema:**\n",
    "    - Fields description: {fields_desc}\n",
    "    - Fields type: {fields_type}\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Use available data information from the fields to create the best possible expected result for the prompt.\n",
    "    - Only state what the expected result should be with no explanations about it.\n",
    "    - The expected result should reflect what the LLM should output after querying BigQuery. In essence, how the format and structure of the data should look like. \n",
    "    - Let the output be in concise sentences.\n",
    "    - Make use of the assumptions when creating the expected result. However, only take the most reasonable parts that are relevant.\n",
    "\n",
    "    **Output format:**  \n",
    "    Expected result: <Your response here>\n",
    "    \"\"\"\n",
    "    \n",
    "    response = generate_response(instructions, temperature=0.2, top_k=20, top_p=0.5)\n",
    "    #print(response)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_code(prompt, fields_type, fields_desc, strategy, keywords, expected_result, assumptions = None):\n",
    "    instructions = f\"\"\"\"\n",
    "    **Prompt:** {prompt}\n",
    "\n",
    "    **Table schema:** \n",
    "    - Data types: {fields_type} \n",
    "    - Descriptions: {fields_desc} \n",
    "    - Table: {full_responses_table_name}\n",
    "\n",
    "    **Strategy:**\n",
    "    - {strategy} \n",
    "\n",
    "    **Keywords:** \n",
    "    - {keywords}\n",
    "\n",
    "    **Expected result:** \n",
    "    - {expected_result}\n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    - {assumptions}\n",
    "\n",
    "    **Constraints:** \n",
    "    - The query is sent to BigQuery. It needs to follow BigQuery syntax.\n",
    "    - Fully follow the strategy\n",
    "    - Fully create a query that aligns with the expected result\n",
    "    - Keep query costs as low as possible\n",
    "\n",
    "    ### **Task:**  \n",
    "    - Generate the best possible BigQuery SQL query that:  \n",
    "    1. Follows the strategy step-by-step without deviation. Treat the strategy as a strict blueprint; implement each step exactly as described.\n",
    "    2. Exclude all Null Values from everywhere (`IS NOT NULL`)\n",
    "\n",
    "    **Query Guidelines:**\n",
    "    - Select only necessary fields; avoid extra data.\n",
    "    - Use accurate column names; no transformations.\n",
    "    - Prefer partition filtering over `EXTRACT()`. Use `DATE_TRUNC(date_column, DATE_PART)` correctly (e.g., `DATE_TRUNC(session_started_date, WEEK)`), without string literals.\n",
    "    - Use approximate counts where possible.\n",
    "    - Consider clustering for better filtering.\n",
    "    - **Exclude NULL values** (`IS NOT NULL`).\n",
    "    - Make use of the assumptions. The assumptions are correct and is incorporated into the prompt.\n",
    "    - Order and keep the data user-friendly and answers the prompt.\n",
    "    - Be careful of LIMIT expects an integer literal or parameter\n",
    "    - The query should only give the user ONE table of result.\n",
    "\n",
    "    Use standard SQL. The query will be sent to **BigQuery**, so DO NOT INCLUDE EXPLANATIONS. Make sure the query is VALID. Do not hallucinate.\n",
    "    \"\"\"\n",
    "\n",
    "    code = generate_response(instructions, temperature=0.1, top_k=20, top_p=0.2)\n",
    "    code.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    #print(code)\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(prompt, fields_type, fields_desc, query, expected_result, assumptions, strategy):\n",
    "    instructions = f\"\"\"\n",
    "    ### **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    ### **Strategy for creating SQL code:** \n",
    "    {strategy}\n",
    "\n",
    "    ### **SQL Query:** \n",
    "    {query}\n",
    "\n",
    "    ### **Expected result:** \n",
    "    {expected_result}\n",
    "\n",
    "    ### **Table schema:** \n",
    "    - Fields descriptions: {fields_desc}\n",
    "    - Fields type: {fields_type}\n",
    "\n",
    "    ### **Task:**  \n",
    "    - Does this query align with the combination of the prompt, the expected result?\n",
    "    - Will the syntax work for BigQuery?\n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - Assume the query is incorrect unless there is strong evidence it is correct.  \n",
    "    - If answering \"Yes,\" to a task, explicitly explain why.  \n",
    "    - If answering \"No,\" to a task, identify the issue and explain why it does not meet the requirement.  \n",
    "    - Look at the query and see if the code makes sense and produces reasonable result.\n",
    "    - Answer the task questions indepnedently from each other.\n",
    "    - Follow the output format.\n",
    "    \n",
    "    ### **Output format:**  \n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    response = generate_response(instructions, temperature=0.1, top_k=30, top_p=0.3)\n",
    "\n",
    "    #print(response)\n",
    "\n",
    "    lines = response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    for line in lines:\n",
    "        if \".\" in line:  # Ensure there is a comma before splitting\n",
    "            first, second = line.split(\".\", 1)  # Split only at the first comma\n",
    "            first_part.append(first.strip())  # Store the first part (column name)\n",
    "            second_part.append(second.strip())  # Store the second part (description)\n",
    "\n",
    "    check_list = []\n",
    "    for i in range(len(first_part)):\n",
    "        if first_part[i] == \"No\":\n",
    "            check_list.append(second_part[i])\n",
    "\n",
    "    return check_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sql_error(prompt, keywords, expected_result, sql_code, error, fields_type, fields_desc, strategy):\n",
    "    instructions = f\"\"\"\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Important keywords:**\n",
    "    - {keywords}\n",
    "\n",
    "    **Strategy for creating SQL code:**\n",
    "    - {strategy}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected_result}\n",
    "    \n",
    "    ### **Original SQL Query (Faulty):**\n",
    "    {sql_code}\n",
    "\n",
    "    ### **Error Message:** \n",
    "    {error}\n",
    "\n",
    "    ### **Table Details:** \n",
    "    - Table name: {full_responses_table_name}\n",
    "    - Field data types: {fields_type}\n",
    "    - Field descriptions: {fields_desc}\n",
    "\n",
    "    ### **Task:** \n",
    "    - Review the query and update the query to solve the error while adhering to the prompt, keywords, strategy, and expected result:\n",
    "    \n",
    "    ### **Guidelines:** \n",
    "    - Look at the error and identify where in the code the error exists.\n",
    "    - Look at the numbers [xx, xx]\n",
    "    - Resolve the issue by identifying and changing the code appropriately.\n",
    "\n",
    "    ### **Output:**  \n",
    "    Please provide only the corrected SQL query. Ensure the corrected query is syntactically and logically sound, and adheres to the provided guidelines and constraints.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    response = generate_response(instructions, temperature=0.1, top_k=40, top_p=0.3)\n",
    "    #print(response)\n",
    "\n",
    "    return response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_interpretation(prompt, result, code, assumptions):\n",
    "    instructions = f\"\"\"\n",
    "    ### **Prompt:**\n",
    "    {prompt}  \n",
    "\n",
    "    ### **SQL code:**   \n",
    "    {code}  \n",
    "\n",
    "    ### **Data:**   \n",
    "    {result}  \n",
    "\n",
    "    ### **Assumptions:**   \n",
    "    {assumptions}  \n",
    "\n",
    "    ### **Task:**  \n",
    "    Analyze the provided dataset and generate a meaningful interpretation that answers the given prompt in a user-friendly manner.  \n",
    "\n",
    "    ### **Steps:**  \n",
    "    1. **Answer the question directly.** Provide a clear, data-driven response.  \n",
    "    2. **Extract key insights.** Identify trends, anomalies, or correlations that are not immediately obvious.  \n",
    "    3. **Use external knowledge when relevant.** If applicable, explain insights using common patterns or domain knowledge.  \n",
    "    4. **Focus on the overall pattern** rather than unnecessary details unless a specific outlier is crucial.  \n",
    "    5. **State relevant assumptions.** Only include assumptions that impact the interpretation of result (avoid discussing column names, data types, or table structures).  \n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - **Be concise.** Prioritize clarity over lengthy explanations.  \n",
    "    - **Use a structured format.** Keep responses readable with bullet points and section headings.  \n",
    "    - **Avoid redundant details.** Don’t restate information that is already evident from the dataset.  \n",
    "    - **Ignore missing table schema details.** Focus on strategy, definitions, and calculations instead. Do not focus on BigQuery table assumptions.\n",
    "    - **Assistant with a friendly tone.** Speak to the user as if this is the data you have to asnwer the prompt. Make objective statements and discuss uncertainties when possible.  \n",
    "    - **BigQuery.** The data is extracted from BigQuery with (U.S weekday numbering convention e.g. Sunday is 1 and Monday is 2).\n",
    "    - **Use the code for interpretation** The SQL code that extracts the data contains information which explains certain assumptions and why the data looks the way it does. Make use of the code when making assumptions.\n",
    "\n",
    "    ### **Expected Output Format:**  \n",
    "    1. **Best Answer to the Prompt** (direct response)  \n",
    "    2. **Key Insights & Trends** (summary of findings)  \n",
    "    3. **Relevant Assumptions** (only those impacting interpretation of the result)  \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    final_answer_response = generate_response(instructions, temperature=0.3, top_k=40, top_p=0.6)\n",
    "\n",
    "    \n",
    "\n",
    "    return final_answer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiAgent = DataQueryAgent(project_name, bigquery_client, generate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Where are our users from?\"\n",
    "#prompt = \"Which companies have the highest engagement?\"\n",
    "#prompt = \"Which customers have the most sessions?\"\n",
    "#prompt = \"Based on the bigger customers; what days and times is the best for performing updates, maintenance?\"\n",
    "#prompt = \"At what times and days are people online the least?\"\n",
    "#prompt = \"How do system outages impact user behavior? \"\n",
    "#prompt = \"How did the user behavior change between 30th december 2024, 31th december 2024, 1th january 2025 and 2nd january 2025? \"\n",
    "#prompt = \"Do performance issues correlate with a drop in activity?\"\n",
    "#prompt = \"What combinations of browser and os are the worst according to performance?\"\n",
    "#prompt = \"Based on user behavior, what will the peak activity hours be tomorrow?\"\n",
    "#prompt = \"How does app performance affect user engagement and retention?\"\n",
    "#prompt = \"Which devices and OS versions are experiencing the worst performance?\"\n",
    "prompt = \"Vilka OS system och enheter är sämst enligt performance?\"\n",
    "#prompt = \"Can you see a pattern if you compare Network Latency, Page Load Fails, Page Loading Time and Device and browsers?\"\n",
    "#prompt = \"Can you calculate the monthly stickiness for the products in 2024?\"\n",
    "#prompt = \"Can you calculate the WAU/MAU stickiness for the products for all weeks in 2024?\"\n",
    "#prompt = \"Are there any insights in the correlation between the size of cutsomers and have huge page load times?\"\n",
    "#prompt = \"What are the network latency & slow load times observed during hours when users are most active\"\n",
    "#prompt = \"How much did the total session time increase or decrease in percentage and number between each month in 2025 compared to the months in 2024? Can you divide into user roles\"\n",
    "#prompt = \"For all Windows users, is Edge or Chrome better according to performance? Look for browsers that contain the name either edge or chrome. Compare all versions.\"\n",
    "#prompt = \"What devices are mostly used? and what dimensions are they?\"\n",
    "#prompt = \"Traffic Patterns & Peak Usage\"\n",
    "#prompt = \"System Performance & Browser Issues\"\n",
    "#prompt = \"Extract top 10 customers with longest session times in 2024, show the number of unique users and total sessions as well\"\n",
    "prompt = \"When are our users the least active? Give top' 10 combinations of days and times. Segment it into 2 hours so for example 0-2am, 2-4am and so on\"\n",
    "#prompt = \"Make a table of recurring feedback themes that occur at specific times of the year or at specific times of the month showing theme recurring interval (monthly, yearly, quarterly) and typical time in that interval.\"\n",
    "\n",
    "data, interpretation = aiAgent.process_prompt(prompt)\n",
    "print(data)\n",
    "#print(data.to_string())\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Which customers have the most sessions?\"\n",
    "prompt = \"Can you calculate the monthly stickiness for the customer with the highest stickiness in each module in 2024?\"\n",
    "#prompt = \"Can you calculate the monthly stickiness for each of the module in 2024?\"\n",
    "#prompt = \"How much did the total session time increase or decrease in percentage and number between each month in 2025 compared to the months in 2024? Can you divide into user roles\"\n",
    "#prompt = \"Based on the bigger customers; what days and times is the best for performing updates, maintenance?\"\n",
    "#prompt = \"When are our users the least active? Give top' 10 combinations of days and times. Segment it into 2 hours so for example 0-2am, 1-3am and so on\"\n",
    "#prompt = \"Extract top 10 customers with longest session times in 2024, show the number of unique users and total sessions as well\"\n",
    "#prompt = \"How much did the total session time increase or decrease in percentage and number between each month in 2025 compared to the months in 2024? Can you divide into user roles\"\n",
    "#prompt = \"Which customers are the most sticky for which parts of the product?\"\n",
    "#prompt = \"Which customers are the most sticky for each of the module?\"\n",
    "#prompt = \"Whats the customer lifetime value of my product?\"\n",
    "#prompt = \"Which customers have the longest average session length amongst its leaders?\"\n",
    "#prompt = \"Are there Traffic Patterns that we should be extra awere of?\"\n",
    "#prompt = \"42\"\n",
    "response = aiAgent.process_prompt(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQueryAgent:\n",
    "    def __init__(self, project_id: str, bigquery_client, generate_response_fn):\n",
    "        self.client = bigquery_client\n",
    "        self.project_id = project_id\n",
    "        self.generate_response = generate_response_fn\n",
    "\n",
    "    \n",
    "    def process_prompt(self, user_input):\n",
    "        keywords = extract_keywords(user_input)\n",
    "        fields_type, fields_desc = field_selection(user_input, keywords)\n",
    "        assumptions = self.make_assumptions(user_input, fields_type, fields_desc, keywords)\n",
    "        assumptions = self.refine_assumptions(user_input, assumptions)\n",
    "        \n",
    "        # Re-evaluate query parameters\n",
    "        keywords = extract_keywords(user_input, assumptions)\n",
    "        fields_type, fields_desc = field_selection(user_input, keywords, assumptions)\n",
    "        expected_result = expected(user_input, fields_type, fields_desc, assumptions)\n",
    "        \n",
    "        # Generate a strategy, generate code, and verify SQL query\n",
    "        sql_code, strategy = self.generate_valid_sql(user_input, fields_type, fields_desc, keywords, expected_result, assumptions)\n",
    "        if not sql_code:\n",
    "            return \"Failed to generate a reasonable SQL query after 3 attempts.\"\n",
    "        \n",
    "        # Validate SQL query using BigQuery dry run\n",
    "        valid_result, result_df = self.validate_sql_query(prompt, keywords, expected_result, sql_code, fields_type, fields_desc, strategy)\n",
    "        if not valid_result:\n",
    "            return \"Failed to generate a valid SQL query after 3 attempts.\"\n",
    "        \n",
    "        # Process query results\n",
    "        result_df = result_df.map(lambda x: \"Missing Data\" if x in {\"\", \"None\"} else x).dropna()\n",
    "        interpretation = result_interpretation(user_input, result_df, sql_code, assumptions)\n",
    "        \n",
    "        return result_df, interpretation\n",
    "    \n",
    "\n",
    "    def refine_assumptions(self, user_input, assumptions):\n",
    "        while True:\n",
    "            user_clarifications = input(f\"Are the following assumptions correct?\\n\\n{assumptions}\")\n",
    "            if user_clarifications.lower() in {\"\", \"yes\", \"y\"}:\n",
    "                print(assumptions)\n",
    "                print(\"----------------------------------------------------------------------------------\")\n",
    "                return assumptions\n",
    "            assumptions = self.interpret_clarification(user_input, assumptions, user_clarifications)\n",
    "    \n",
    "\n",
    "    def generate_valid_sql(self, user_input, fields_type, fields_desc, keywords, expected_result, assumptions):\n",
    "        for attempt in range(3):\n",
    "            strategy = self.create_strategy(user_input, fields_type, fields_desc, keywords, expected_result, assumptions)\n",
    "            sql_code = create_sql_code(user_input, fields_type, fields_desc, strategy, keywords, expected_result, assumptions)\n",
    "            validation_errors = verify(user_input, fields_type, fields_desc, sql_code, expected_result, assumptions, strategy)\n",
    "            if not validation_errors:\n",
    "                return sql_code, strategy \n",
    "        \n",
    "        return None, None\n",
    "\n",
    "\n",
    "    def validate_sql_query(self, prompt, keywords, expected, sql_code, fields_type, fields_desc, strategy):\n",
    "        \"\"\"Performs a dry run of the SQL query to check validity.\"\"\"\n",
    "        job_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "        \n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                query_job = self.client.query(sql_code, job_config=job_config)\n",
    "                query_job.result()\n",
    "                print(f\"Query is valid. Estimated processing: {query_job.total_bytes_processed / 1e9:.2f} GB.\")\n",
    "                return True, self.client.query(sql_code).to_dataframe()\n",
    "            except Exception as e:\n",
    "                print(f\"Query validation failed (Attempt {attempt + 1}/3): {e}\")\n",
    "                sql_code = correct_sql_error(prompt, keywords, expected, sql_code, e, fields_type, fields_desc, strategy)\n",
    "        return False, None\n",
    "    \n",
    "\n",
    "    def make_assumptions(self, prompt, fields_type, fields_desc, keywords):\n",
    "        instructions = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "        ### **Table Info:**\n",
    "        - Fields Type: {fields_type}\n",
    "        - Fields Description: {fields_desc}\n",
    "        - Table name: {full_responses_table_name}\n",
    "        \n",
    "        ### **Constraints:**\n",
    "        - Use only given fields.\n",
    "        - No external data or assumptions beyond the provided fields.\n",
    "        \n",
    "        ### **Task:**\n",
    "        - Propose short, reasonable, and user-friendly assumptions to resolve potential ambiguities in the prompt, leveraging the table info implicitly.\n",
    "        - Propose reasonable definitions, calculations and other clarifications on the prompt.\n",
    "\n",
    "        ### **Guidelines:**\n",
    "        - Base assumptions on the most likely intent of the prompt, and keywords, informed by available data patterns from the table.\n",
    "        - Keep assumptions simple and verifiable by the user, who lacks table schema knowledge.\n",
    "        - Remember that the user cannot read all assumptions if they are too long. That is why it is important to keep each assumptions short as punctual.\n",
    "        - Output a numeric list.\n",
    "        - Do NOT generate SQL code.\n",
    "        \n",
    "        ### **Output Format:**\n",
    "        1. ...\n",
    "        2. ...\n",
    "        \"\"\"\n",
    "        return self.generate_response(instructions, temperature=0.1, top_k=20, top_p=0.3)\n",
    "    \n",
    "\n",
    "    def interpret_clarification(self, prompt, assumptions, user_clarifications):\n",
    "        instructions = f\"\"\"\n",
    "        ### **Initial Prompt:** {prompt}\n",
    "        ### **Current Assumptions:** {assumptions}\n",
    "        ### **User Clarifications:** {user_clarifications}\n",
    "        ### **Task:**\n",
    "        - Update assumptions based on clarifications.\n",
    "        - If no change is needed, return the current assumptions.\n",
    "        \"\"\"\n",
    "        return self.generate_response(instructions, temperature=0.2, top_k=40, top_p=0.5)\n",
    "    \n",
    "\n",
    "    def create_strategy(self, prompt, fields_type, fields_desc, keywords, expected_result, assumptions):\n",
    "        instructions = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "        ### **Expected Result:** {expected_result}\n",
    "        ### **Table Details:**\n",
    "        - Fields Type: {fields_type}\n",
    "        - Fields Description: {fields_desc}\n",
    "        ### **Assumptions:**\n",
    "        - {assumptions}\n",
    "        ### **Constraints:** \n",
    "        - Use only the fields in the specified table—no external data or tables.  \n",
    "        - Base the strategy solely on the given prompt, keywords, expected result, and table details.  \n",
    "        ### **Task:** \n",
    "        - Suggest specific SQL operations in a step-by-step tailored to the prompt, assumptions and expected result.\n",
    "        - Make sure the steps guide the query to be as user friendly as possible.\n",
    "\n",
    "        ### **Guidelines:**\n",
    "        - Have many steps so that nothing is lost.\n",
    "        - Do not generate executable SQL.\n",
    "        - Keep the strategy concise and focused—no fluff or extraneous steps.\n",
    "\n",
    "         ### **Output:**   \n",
    "        - **Step-by-Step Strategy:** (\"Title/Purpose\" - do this)  \n",
    "        \"\"\"\n",
    "        strategy = self.generate_response(instructions, temperature=0.1, top_k=40, top_p=0.5)\n",
    "        #print(strategy)\n",
    "\n",
    "        return strategy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
