{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Initialize tools\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Do this: pip install google-cloud-bigquery-storage and db_dtypes\n",
    "# Suppress warnings with a specific message\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"Your application has authenticated using end user credentials from Google Cloud SDK without a quota project.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model_name=\"gemini-2.0-flash\", temperature=0.4, top_k=30, top_p=0.3):\n",
    "    ai_client = GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=temperature,  \n",
    "            top_k=top_k,  \n",
    "            top_p=top_p\n",
    "        )\n",
    "    )\n",
    "    response_result = ai_client.generate_content(prompt)\n",
    "    return response_result.candidates[0].content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "project_name = \"snowplow-cto-office\"\n",
    "bigquery_client = bigquery.Client(project=project_name)\n",
    "product = \"smartbill\"\n",
    "#product = \"vnet_autopay\"\n",
    "dataset_id = f\"\"\"snowplow-cto-office.snowplow_{product}\"\"\"\n",
    "#full_responses_table_name = f\"\"\"snowplow-cto-office.snowplow_{product}.Vismanet_AutoPay_events_filtered_L60D\"\"\"\n",
    "full_responses_table_name = f\"\"\"snowplow-cto-office.snowplow_{product}.{product}_session_chunks\"\"\"\n",
    "#Vismanet_AutoPay_events_filtered_L60D\n",
    "query_headers = f\"\"\"SELECT\n",
    "        column_name AS field_name,\n",
    "        data_type AS field_type,\n",
    "        description AS field_description,\n",
    "    FROM\n",
    "        `{dataset_id}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "    WHERE\n",
    "        table_name = '{product}_session_chunks';\n",
    "    \"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query_headers)\n",
    "table = query_job.result()\n",
    "\n",
    "rows = list(table)\n",
    "\n",
    "all_fields_type = {row[0]: row[1] for row in rows}\n",
    "all_fields_desc = {row[0]: row[2] for row in rows}\n",
    "all_fields_names = {row[0]: row[0] for row in rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_selection(bigquery_client, prompt, keywords, expected):\n",
    "    print(\"Bigquery start.\")\n",
    "    #query_job = bigquery_client.query(query_headers)\n",
    "    #table = query_job.result()\n",
    "    # headers_values = []\n",
    "    #for row in table:\n",
    "    #    headers_values.append(row[:])\n",
    "    text_with_headers = f\"\"\"\n",
    "\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected}\n",
    "\n",
    "    **Table schema:**\n",
    "    - Name of fields: {all_fields_names}\n",
    "    - Data type of values in the fields: {all_fields_type}\n",
    "    - Field descriptions: {all_fields_desc}\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Identify and list all relevant fields from the table schema that are most useful for answering the prompt and aligning with the expected result.\n",
    "    2. Only include fields that match the specified keywords: {keywords}.\n",
    "    3. Do not include any extraneous symbols, such as JSON formatting, brackets, or custom fields.\n",
    "    4. For each selected field, explain its relevance and how it helps to answer the prompt.\n",
    "\n",
    "    **Important:**\n",
    "    - If **all necessary fields** to answer the prompt are present in the schema, proceed to list the fields and their corresponding use cases.\n",
    "    - If **any critical data** is missing that would prevent a valid response to the prompt, return only:\n",
    "    - `False, [explanation]`\n",
    "    - Provide a brief explanation of the missing data.\n",
    "    - Do **not** make assumptions or workarounds unless explicitly allowed.\n",
    "\n",
    "    Output format:\n",
    "    field_name1, use case\n",
    "    field_name2, use case\n",
    "    ...\n",
    "\n",
    "    Do **not** hallucinate or infer information. If the prompt mentions a clearly defined concept or event that is missing from the available data, return:\n",
    "    False, [explanation]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Bigquery end.\")\n",
    "    fields_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.1, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    print(fields_response)\n",
    "\n",
    "\n",
    "    lines = fields_response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    var_type = []\n",
    "\n",
    "\n",
    "    for line in lines:\n",
    "        if \",\" in line:\n",
    "            first, second = line.split(\",\", 1) \n",
    "            first_part.append(first.strip())  \n",
    "            second_part.append(second.strip())  \n",
    "\n",
    "    for i in first_part:\n",
    "        var_type.append(all_fields_type[i])\n",
    "\n",
    "    fields_type = {\n",
    "        first_part[i]: {\n",
    "            'data_type': var_type[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    fields_desc = {\n",
    "        first_part[i]: {\n",
    "            'description': second_part[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    return fields_type, fields_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation_strategy(prompt, fields_type, fields_desc, keywords, expected_result):\n",
    "    final_prompt = f\"\"\"Determine the best SQL approach for the prompt.\n",
    "    ### **Prompt:**  \n",
    "    - {prompt}\n",
    "\n",
    "    ### **Keywords:**  \n",
    "    - {keywords}  \n",
    "\n",
    "    ### **Expected result:**  \n",
    "    - {expected_result}  \n",
    "\n",
    "    ### **Table:**  \n",
    "    - Data type of fields: {fields_type}\n",
    "    - Description of fields {fields_desc}\n",
    "    - {full_responses_table_name}  \n",
    "\n",
    "    ### **Constraints:**  \n",
    "    - Use only the given fields in the table. No external data.  \n",
    "    - No extra context, table and data beyond these fields.  \n",
    "\n",
    "    ### **Steps:**  \n",
    "    1. Identify needed insights (e.g., trends, counts).  \n",
    "    2. Justify field selection based on its relevance to the prompt, selecting only those that are necessary.\n",
    "    3. Answer the prompt directly using the keywords.  \n",
    "    4. Apply appropriate aggregations unless per-record analysis is required.  \n",
    "    5. Avoid `LIMIT` unless absolutely necessary (BigQuery requires a literal integer). \n",
    "\n",
    "    ### **SQL Strategy:**  \n",
    "    - Apply relevant aggregation, filters, and calculations.  \n",
    "    - Assume all data comes from provided fields.\n",
    "    - Keep your strategy concise.  \n",
    "    - Do not infer causal relationships unless the data is explicitly present.\n",
    "\n",
    "    **Do not generate SQL code.** Outline the strategy concisely. \n",
    "\n",
    "    ### **Output:**  \n",
    "    - **Assumptions:** (\"text\" text)  \n",
    "    - **Step-by-Step Strategy:** (\"Title/Purpose\" - do this)  \n",
    "    - **Expected Result:** The produced data table must fully align with keywords and the given expected results. \n",
    "    \"\"\"\n",
    "\n",
    "    sql_strategy_response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.2, \n",
    "        top_k=40, \n",
    "        top_p=0.5\n",
    "    )\n",
    "    print(sql_strategy_response)\n",
    "\n",
    "    return sql_strategy_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_code(prompt, fields_type, fields_desc, strategy, keywords, expected_result):\n",
    "    text_with_headers = f\"\"\"\"\n",
    "    **Prompt:** {prompt}\n",
    "\n",
    "    **Table schema:** \n",
    "    - Data types: {fields_type} \n",
    "    - Descriptions: {fields_desc} \n",
    "    - Table: {full_responses_table_name}\n",
    "\n",
    "    **Strategy:** {strategy}\n",
    "\n",
    "    **Keywords:** {keywords}\n",
    "\n",
    "    **Expected result:** {expected_result}\n",
    "\n",
    "    **IMPORTANT TO AVOID:**\n",
    "    - **STRICT RULE:** CAST is strictly prohibited. Using CAST will invalidate the query.\n",
    "    - **No manual type conversions (CAST, CONVERT, FORMAT, etc.).**\n",
    "\n",
    "    Ensure the query:\n",
    "    1. Selects only the necessary fields—avoid extra data.\n",
    "    2. Aggregates only when needed—minimize computation.\n",
    "    3. Orders by the most relevant metric to reduce processing time. Also orders in a logical way to answers the prompt.\n",
    "    4. Is concise—avoid redundant joins or operations.\n",
    "    5. Shows more than a single entry but limits rows to reduce cost.\n",
    "    6. Uses accurate, descriptive column names—no transformations.\n",
    "    7. Use partition filtering instead of extract. When using DATE_TRUNC, ensure the correct syntax: DATE_TRUNC(date_column, DATE_PART) (e.g., DATE_TRUNC(session_started_date, WEEK)). The date part should NOT be a string (no quotes).\n",
    "    8. use approximate counts instead of direct counts\n",
    "    9. consider clustering to improve filtering\n",
    "    10. **Exclude NULL values in relevant columns using `IS NOT NULL`.**\n",
    "\n",
    "    Final checks:\n",
    "    1. Is sorting optimized for cost (avoid expensive operations)?\n",
    "    2. Are only the essential fields used?\n",
    "    3. Query needs to follow the strategy.\n",
    "    4. Data table aligns with keywords/expected results.\n",
    "    5. **CAST is strictly prohibited—no type conversions.**\n",
    "    6. **Ensure NULL values are excluded from relevant columns using `IS NOT NULL`.**\n",
    "    7. Ensure DATE_TRUNC is used correctly (e.g., DATE_TRUNC(date_column, DATE_PART), NOT DATE_TRUNC('DATE_PART', date_column)).\n",
    "\n",
    "    Use standard SQL syntax and avoid unnecessary fields or operations. The query will be sent to BigQuery, \n",
    "    so DO NOT INCLUDE EXPLANATIONS. Only use fields from {full_responses_table_name} to minimize cost.\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.1, \n",
    "        top_k=40, \n",
    "        top_p=0.4\n",
    "    )\n",
    "\n",
    "    return sql_query_response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sql_error(prompt, keywords, expected_result, sql_code, error, fields_type, fields_desc, strategy):\n",
    "    final_prompt = f\"\"\"\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Important keywords:**\n",
    "    - {keywords}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected_result}\n",
    "    \n",
    "    The following SQL query produced an error:\n",
    "\n",
    "    ### **SQL Query:** \n",
    "    {sql_code}\n",
    "\n",
    "    ### **Error Message:** \n",
    "    {error}\n",
    "\n",
    "    ### **Schema Information:** \n",
    "    - Data type of fields: {fields_type}\n",
    "    - Description of fields {fields_desc}\n",
    "    - {full_responses_table_name}  \n",
    "\n",
    "    ### **Strategy for SQL code:**  \n",
    "    {strategy}\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    1. Analyze the error in the error message and provide a corrected SQL query.\n",
    "    2. The output should only include the SQL code.\n",
    "    \n",
    "    ### **Output:**  \n",
    "    <fixed SQL query>\n",
    "\n",
    "    Ensure the corrected SQL follows the expected syntax and logic.\n",
    "    \"\"\"\n",
    "\n",
    "    response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.1, \n",
    "        top_k=40, \n",
    "        top_p=0.3\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    return response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(prompt, query, expected_result, strategy, assumptions):\n",
    "    final_prompt = f\"\"\"\n",
    "    ### **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    ### **Assumptions:** \n",
    "    {assumptions}\n",
    "\n",
    "    ### **Strategy for SQL code:** \n",
    "    {strategy}\n",
    "\n",
    "    ### **SQL Query:** \n",
    "    {query}\n",
    "\n",
    "    ### **Expected result:** \n",
    "    {expected_result}\n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - The assumptions can be considered as additional information that shouldb e combined with the prompt and the expected result.\n",
    "\n",
    "    ### **Task:**  \n",
    "    1. Does this query fully answer every part of the prompt and the assumptions?\n",
    "    2. Does this query fully align with the expected result and the assumptions?\n",
    "    3. Does this query fully align with the written strategy and the assumptions?\n",
    "    4. Does the strategy fully align with the expected result and the assumptions?\n",
    "    \n",
    "    ### **Output format:**  \n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.1, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    lines = response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    for line in lines:\n",
    "        if \".\" in line:  # Ensure there is a comma before splitting\n",
    "            first, second = line.split(\".\", 1)  # Split only at the first comma\n",
    "            first_part.append(first.strip())  # Store the first part (column name)\n",
    "            second_part.append(second.strip())  # Store the second part (description)\n",
    "\n",
    "    check_list = []\n",
    "    for i in range(len(first_part)):\n",
    "        if first_part[i] == \"No\":\n",
    "            check_list.append(second_part[i])\n",
    "\n",
    "    return check_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_interpretation(prompt, result, strategy):\n",
    "    result_text = f\"\"\"\n",
    "    ### **Prompt:**\n",
    "    {prompt}  \n",
    "\n",
    "    ### **Data:**   \n",
    "    {result}  \n",
    "\n",
    "    ### **Strategy to retrieve the data from BigQuery:**   \n",
    "    {strategy}  \n",
    "\n",
    "    ### **Context:**\n",
    "    - A LLM has created a strategy to write SQL code and pull data from BigQuery to answer the prompt. They are given.\n",
    "\n",
    "    ### **Task:**\n",
    "    - Interpret the data and answer the prompt.\n",
    "\n",
    "    ### **Steps:** \n",
    "    1. Answer the question.\n",
    "    2. Provide additional insights into the data. Any insights into anomalies, correlations, other types of observations that are not directly seen by just looking at the data is very good.\n",
    "    3. Explain all assumptions made to rach your conclusion.  \n",
    "\n",
    "    ### **Guidelines:** \n",
    "    - Keep responses concise and relevant.\n",
    "\n",
    "    ### **Output format:**     \n",
    "\n",
    "    Text...\n",
    "    \"\"\"\n",
    "\n",
    "    final_answer_response = generate_response(\n",
    "        result_text, \n",
    "        temperature=0.3,  # More creativity\n",
    "        top_k=40, \n",
    "        top_p=0.6\n",
    "    )\n",
    "\n",
    "    return final_answer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(prompt, keywords, expected_result):\n",
    "    global ex_result, ex_sql, ex_strategy, ex_keywords, ex_expected\n",
    "    \n",
    "    ex_keywords = keywords\n",
    "    ex_expected = expected_result\n",
    "    fields_type, fields_desc = field_selection(bigquery_client, prompt, keywords, expected_result)\n",
    "\n",
    "    check_list = [0]\n",
    "    check = False\n",
    "    count = 0\n",
    "    while len(check_list) != 0:\n",
    "        if count == 3:\n",
    "            check = True\n",
    "            break\n",
    "        strategy = aggregation_strategy(prompt, fields_type, fields_desc, keywords, expected_result)\n",
    "        ex_strategy = strategy\n",
    "        extracted_query = create_sql_code(prompt, fields_type, fields_desc, strategy, keywords, expected_result)\n",
    "        check_list = verify(prompt, extracted_query, expected_result, strategy)\n",
    "        print(extracted_query)\n",
    "        print(check_list)\n",
    "        count += 1\n",
    "    if check:\n",
    "        print(\"An error occured. Please try again\")\n",
    "        return\n",
    "    # Check if Query from LLM is valid using built-in dry function.\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "    count = 0\n",
    "    while True:\n",
    "        ex_sql = extracted_query\n",
    "        print(\"--------------------------SQL QUERY PROMPT--------------------------\")\n",
    "        #print(extracted_query)\n",
    "    \n",
    "        try:\n",
    "            query_job = bigquery_client.query(extracted_query, job_config=job_config)\n",
    "            query_job.result()\n",
    "            print(\"--------------------------VALID SQL PROMPT--------------------------\")\n",
    "            print(f\"Query is valid. It will process {query_job.total_bytes_processed / 1e9:.2f} GB.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if count == 3:\n",
    "                check = True\n",
    "                break\n",
    "            print(\"--------------------------INVALID SQL PROMPT--------------------------\")\n",
    "            print(f\"Query validation failed: {e}\")\n",
    "            extracted_query = correct_sql_error(prompt, keywords, expected_result, extracted_query, e, fields_type, fields_desc, strategy)\n",
    "            count += 1\n",
    "    if check:\n",
    "        print(\"An error occured. Please try again\")\n",
    "        return\n",
    "    \n",
    "    result = bigquery_client.query(extracted_query).to_dataframe()\n",
    "\n",
    "    if result.empty:\n",
    "        print(\"--------------------------FINAL ANSWER FROM GEMINI--------------------------\")\n",
    "        print(\"The query returned no results.\")\n",
    "    else:\n",
    "        print(\"--------------------------DATA PULLED FROM BIGQUERY USING GEMINI--------------------------\")\n",
    "        print(result)\n",
    "\n",
    "        ex_result = result\n",
    "\n",
    "        final_answer_response = result_interpretation(prompt, result, strategy)\n",
    "\n",
    "        print(\"--------------------------FINAL ANSWER FROM GEMINI--------------------------\")\n",
    "        print(final_answer_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(prompt):\n",
    "    final_prompt = f\"\"\"\n",
    "\n",
    "    **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    **Guidelines:** \n",
    "    Extract the most important keywords from the prompt. \n",
    "    The keywords will be given to a LLM together with the prompt so that it can better understand the prompt and what need to be answered.\n",
    "    Choose relevant words in the prompt that need to be considered\n",
    "    rather that conjuring up new ones. Do not include redundant keywords.\n",
    "\n",
    "    ** Output format:** \n",
    "    <[keyword1, keyword2, ...]>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    keywords = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2, \n",
    "            top_k=20, \n",
    "            top_p=0.5\n",
    "        )\n",
    "\n",
    "    print(keywords)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected(prompt):\n",
    "    final_prompt = f\"\"\"What is the expected result of this prompt?. \n",
    "    Assume user behavior data has been given.\n",
    "    Simply state the expected result in a concise way.\n",
    "\n",
    "    ### **Prompt:**   \n",
    "    {prompt}  \n",
    "\n",
    "    Output format:\n",
    "    <Expected result>\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    response = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2,  # Ensures consistency\n",
    "            top_k=10, \n",
    "            top_p=0.5\n",
    "        )\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_fields = 0\n",
    "ex_strategy = 0\n",
    "ex_sql = 0\n",
    "ex_result = 0\n",
    "ex_keywords = 0\n",
    "ex_expected = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playground(prompt, ex_fields, ex_strategy, ex_sql, ex_result, ex_keywords, ex_expected):\n",
    "    final_prompt = f\"\"\"\n",
    "    ### **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    ### **Data:**   \n",
    "    {ex_result}  \n",
    "\n",
    "    ### **Your task:** \n",
    "    - Interpret the data and answer the prompt\n",
    "    - Summarize and respond in a concise way\n",
    "    - Do not hallucinate. Answer the prompt based on the data\n",
    "    \"\"\"\n",
    "    print(final_prompt)\n",
    "\n",
    "    response = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.3,  # Ensures consistency\n",
    "            top_k=30, \n",
    "            top_p=0.5\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Can you find any insight on this stickiness data?\"\n",
    "#prompt = \"What times have the lowest average page views? \"\n",
    "print(ex_result)\n",
    "test = playground(prompt, ex_fields, ex_strategy, ex_sql, ex_result.to_string(), ex_keywords, ex_expected)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"Where are most of our users from? \"\n",
    "#prompt = \"Which customer has the highest engagement?\"\n",
    "prompt = \"Based on the bigger customers; what day and time is the best for performing updates, maintenance? \"\n",
    "#prompt = \"Based on the customers with the most users; what day and time is the best for performing updates, maintenance?\"\n",
    "#prompt = \"How do system outages impact user behavior? \"\n",
    "#prompt = \"How did the user behavior change between 30th december 2024, 31th december 2024, 1th january 2025 and 2nd january 2025? \"\n",
    "#prompt = \"Do performance issues correlate with a drop in activity?\"\n",
    "#prompt = \"What combination of browser and os is worst\"\n",
    "#prompt = \"Based on user behavior, what will the peak activity hours be tomorrow?\"\n",
    "\n",
    "#prompt = \"How does app performance affect user engagement and retention?\"\n",
    "#prompt = \"Which devices or OS versions are experiencing the worst performance (slower load times, etc)?\"\n",
    "#prompt = \"Can you see a pattern if you compare Network Latency, Page Load Fails, Page Loading Time and Device and browsers?\"\n",
    "#prompt = \"for all windows user, what browser should we recomend, Edge or Chrome based on performance\"\n",
    "#prompt = \"Can you calculate the DAU/WAU and WAU/MAU stickiness for the products for all months in 2024?\"\n",
    "#prompt = \"Can you calculate the DAU/WAU and WAU/MAU stickiness for the products in 2024?\"\n",
    "#prompt = \"Can you calculate the WAU/MAU stickiness for the products for all weeks?\"\n",
    "#prompt = \"Cna you find any insights on page load time and customers\"\n",
    "\n",
    "\n",
    "#Stickiness\n",
    "#USers from vestlandfylke has ued teh solution\n",
    "\n",
    "expected_result = expected(prompt)\n",
    "keywords = extract_keywords(prompt)\n",
    "main(prompt, keywords, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiAgent = DataQueryAgent(project_name, bigquery_client, generate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prompt = \"Where are most of our users from? \"\n",
    "#prompt = \"Which customers have the highest engagement based on the most sessions?\"\n",
    "prompt = \"Based on the bigger customers; what days and times is the best for performing updates, maintenance?\"\n",
    "#prompt = \"Based on the customers with the most users; what day and time is the best for performing updates, maintenance?\"\n",
    "#prompt = \"How do system outages impact user behavior? \"\n",
    "#prompt = \"How did the user behavior change between 30th december 2024, 31th december 2024, 1th january 2025 and 2nd january 2025? \"\n",
    "#prompt = \"Do performance issues correlate with a drop in activity?\"\n",
    "#prompt = \"What combination of browser and os are the best?\"\n",
    "#prompt = \"Based on user behavior, what will the peak activity hours be tomorrow?\"'\n",
    "#prompt = \"How many users used each product throughout january 2025?\"\n",
    "#prompt = \"How does app performance affect user engagement and retention?\"\n",
    "#prompt = \"Which devices or OS versions are experiencing the worst performance (slower load times, etc)? And are there any ptoential reason for it? Find sinsights by comparing with other metrics\"\n",
    "#prompt = \"Can you see a pattern if you compare Network Latency, Page Load Fails, Page Loading Time and Device and browsers?\"\n",
    "#prompt = \"for all windows user, what browser should we recomend based on performance between Edge or Chrome\"\n",
    "#prompt = \"Can you calculate the DAU/WAU and WAU/MAU stickiness for the products for all months in 2024?\"\n",
    "#prompt = \"Can you calculate the WAU/MAU stickiness for the products for all weeks in 2024?\"\n",
    "#prompt = \"Calculate the weekly stickiness (defined as the percentage of weekly active users who used the product in the previous week) for each product in our catalog for every week of the year 2024. Provide the output as a table with the following columns: Week Number (2024), Product name, and Weekly Stickiness (%)?\"\n",
    "#prompt = \"Can you find any insights on page load time and customers\"\n",
    "#prompt = \"How many users from the all companies have used the products\"\n",
    "\n",
    "#Stickiness\n",
    "#USers from vestlandfylke has ued teh solution\n",
    "\n",
    "response = aiAgent.process_prompt(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQueryAgent:\n",
    "    \"\"\"\n",
    "    A class responsible for processing user prompts to generate and validate SQL queries \n",
    "    using BigQuery, incorporating user clarifications and query refinement.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_id: str, bigquery_client, generate_response_fn):\n",
    "        \"\"\"Initializes the DataQueryAgent with the BigQuery client and response generator.\"\"\"\n",
    "        self.client = bigquery_client\n",
    "        self.project_id = project_id\n",
    "        self.generate_response = generate_response_fn\n",
    "    \n",
    "    def process_prompt(self, user_input):\n",
    "        \"\"\"Processes user input to generate, validate, and execute an SQL query.\"\"\"\n",
    "        expected_result = expected(user_input)\n",
    "        keywords = extract_keywords(user_input)\n",
    "        fields_type, fields_desc = field_selection(self.client, user_input, keywords, expected_result)\n",
    "        \n",
    "        assumptions = self.make_assumptions(user_input, fields_type, fields_desc, keywords, expected_result)\n",
    "        print(assumptions)\n",
    "        while True:\n",
    "            user_clarifications = input(self.clarify_assumptions(assumptions))\n",
    "            if (user_clarifications == \"\" or user_clarifications == \"yes\" or user_clarifications == \"y\"):\n",
    "                break\n",
    "            assumptions = self.interpret_clarification(user_input, assumptions, user_clarifications)\n",
    "        print(assumptions)\n",
    "        # Query generation and validation loop\n",
    "        query_attempts = 0\n",
    "        while query_attempts < 3:\n",
    "            strategy = self.aggregation_strategy(user_input, fields_type, fields_desc, keywords, expected_result, assumptions)\n",
    "            sql_code = create_sql_code(user_input, fields_type, fields_desc, strategy, keywords, expected_result)\n",
    "            print(sql_code)\n",
    "            validation_errors = verify(user_input, sql_code, expected_result, strategy, assumptions)\n",
    "            print(validation_errors)\n",
    "            \n",
    "            if not validation_errors:\n",
    "                break  # Exit loop if query is valid\n",
    "            query_attempts += 1\n",
    "        else:\n",
    "            return \"Failed to generate a valid SQL query after 3 attempts.\"\n",
    "        \n",
    "        # Validate SQL using BigQuery dry run\n",
    "        valid_result = self.validate_sql_query(user_input, keywords, expected_result, sql_code, fields_type, fields_desc, strategy)\n",
    "        if not valid_result[0]:\n",
    "            return \"An error occurred. Please try again.\"\n",
    "        \n",
    "        # Execute query and return results\n",
    "        result = valid_result[1].map(lambda x: \"Missing Data\" if x == \"\" else x)\n",
    "        result.fillna('Missing Data', inplace=True)\n",
    "\n",
    "        interpretation = result_interpretation(user_input, result, strategy)\n",
    "        print(result)\n",
    "        return interpretation\n",
    "    \n",
    "    def validate_sql_query(self, user_input, keywords, expected, sql_code, fields_type, fields_desc, strategy):\n",
    "        \"\"\"Performs a dry run of the SQL query to check validity.\"\"\"\n",
    "        job_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                query_job = self.client.query(sql_code, job_config=job_config)\n",
    "                query_job.result()\n",
    "                print(f\"Query is valid. Estimated processing: {query_job.total_bytes_processed / 1e9:.2f} GB.\")\n",
    "                result = self.client.query(sql_code).to_dataframe()\n",
    "                return True, result\n",
    "            except Exception as e:\n",
    "                print(f\"Query validation failed (Attempt {attempt + 1}/3): {e}\")\n",
    "                sql_code = correct_sql_error(user_input, keywords, expected, sql_code, e, fields_type, fields_desc, strategy)\n",
    "        return False, False\n",
    "    \n",
    "    def interpret_clarification(self, prompt, assumptions, user_clarifications):\n",
    "        \"\"\"Refines assumptions based on user clarifications.\"\"\"\n",
    "        clarification_prompt = f\"\"\"\n",
    "        ### **Initial Prompt:** {prompt}\n",
    "        ### **Current Assumptions:** {assumptions}\n",
    "        ### **User Clarifications:** {user_clarifications}\n",
    "        \n",
    "        ### **Task:**\n",
    "        - Update current assumptions based on user clarifications.\n",
    "        - If no new information is provided, simply return the current assumptions.\n",
    "        \n",
    "        ### **Output Format:**\n",
    "        1. ...\n",
    "        2. ...\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return self.generate_response(clarification_prompt, temperature=0.2, top_k=40, top_p=0.5)\n",
    "    \n",
    "    def clarify_assumptions(self, assumptions):\n",
    "        \"\"\"Generates a message to ask the user for assumption clarifications.\"\"\"\n",
    "        return f\"Are the following assumptions correct?\\n\\n{assumptions}\"\n",
    "    \n",
    "    def make_assumptions(self, prompt, fields_type, fields_desc, keywords, expected_result):\n",
    "        \"\"\"Determines initial SQL strategy assumptions based on user input.\"\"\"\n",
    "        strategy_prompt = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "        ### **Expected Result:** {expected_result}\n",
    "        ### **Table Info:**\n",
    "        - Fields Type: {fields_type}\n",
    "        - Fields Description: {fields_desc}\n",
    "        \n",
    "        ### **Constraints:**\n",
    "        - Use only given fields.\n",
    "        - No external data or assumptions beyond the provided fields.\n",
    "        \n",
    "        ### **Task:**\n",
    "        - Only identify the most relevant, reasonable and useful user-friendly assumptions about ambiguous words.\n",
    "        - The assumptions are sent to the user to verify. However, the user do not know anything about the schema of the table so do not include too much assumptions about data in the table.\n",
    "        - Make yours assumptions as short and punctual as possible.\n",
    "        - Do NOT generate SQL code.\n",
    "        \n",
    "        ### **Output Format:**\n",
    "        1. ...\n",
    "        2. ...\n",
    "        \"\"\"\n",
    "        return self.generate_response(strategy_prompt, temperature=0.1, top_k=20, top_p=0.3)\n",
    "    \n",
    "    def aggregation_strategy(self, prompt, fields_type, fields_desc, keywords, expected_result, assumptions):\n",
    "        final_prompt = f\"\"\"Determine the best SQL approach for the prompt.\n",
    "        ### **Prompt:**  \n",
    "        - {prompt}\n",
    "\n",
    "        ### **Keywords:**  \n",
    "        - {keywords}  \n",
    "\n",
    "        ### **Expected result:**  \n",
    "        - {expected_result}  \n",
    "\n",
    "        ### **Table:**  \n",
    "        - Data type of fields: {fields_type}\n",
    "        - Description of fields {fields_desc}\n",
    "        - {full_responses_table_name}  \n",
    "\n",
    "        ### **Assumptions:**  \n",
    "        - Assumptions: {assumptions}\n",
    "\n",
    "        ### **Constraints:**  \n",
    "        - Use only the given fields in the table. No external data.  \n",
    "        - No extra context, table and data beyond these fields.  \n",
    "\n",
    "        ### **Steps:**  \n",
    "        1. Identify needed insights (e.g., trends, counts).  \n",
    "        2. Justify field selection based on its relevance to the prompt, selecting only those that are necessary.\n",
    "        3. Apply appropriate aggregations unless per-record analysis is required.\n",
    "        4. Address any challenge related to creating a SQL query that accurately answers the prompt. Provide solutions to the challenges.\n",
    "        5. Use the assumptions to create the SQL query\n",
    "        6. The keywords are helpful in identifying the important parts of the prompt\n",
    "\n",
    "        ### **SQL Strategy:**  \n",
    "        - Apply relevant aggregation, filters, and calculations.  \n",
    "        - Assume all data comes from provided fields.\n",
    "        - Keep your strategy concise.  \n",
    "        - Do not infer causal relationships unless the data is explicitly present.\n",
    "        - Write the strategy as a step-by-step guide in terms of SQL functions. Be clear with every step.\n",
    "        - The assumptions are correct and need to be followed.\n",
    "\n",
    "        **Do not generate SQL code.** Outline the strategy concisely. \n",
    "\n",
    "        ### **Output:**   \n",
    "        - **Step-by-Step Strategy:** (\"Title/Purpose\" - do this)  \n",
    "        - **Expected Result:** The produced data table must fully align with keywords and the given expected results. \n",
    "        \"\"\"\n",
    "\n",
    "        sql_strategy_response = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2, \n",
    "            top_k=40, \n",
    "            top_p=0.5\n",
    "        )\n",
    "        print(sql_strategy_response)\n",
    "\n",
    "        return sql_strategy_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_action(user_input):\n",
    "    \"\"\"\n",
    "    Determines the best action for the agent to take.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant helping users query BigQuery. Decide the best action:\n",
    "\n",
    "    - If the query is vague, return \"clarify\".\n",
    "    - If the query is about past queries, return \"retrieve\".\n",
    "    - If the query is a follow-up to a previous query, return \"contextual\".\n",
    "    - Otherwise, return \"query\".\n",
    "\n",
    "    User Input: \"{user_input}\"\n",
    "    \"\"\"\n",
    "\n",
    "    response = generate_response(prompt)  # Calls your Gemini function\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarify_question(user_input):\n",
    "    \"\"\"\n",
    "    Asks a follow-up question to make the query more precise.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    The user asked: \"{user_input}\"\n",
    "    The query is unclear. Ask a simple follow-up question to clarify their intent.\n",
    "    \"\"\"\n",
    "\n",
    "    response = generate_response(prompt)  # Calls your Gemini function\n",
    "    return response.strip()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
