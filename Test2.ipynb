{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Initialize tools\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Do this: pip install google-cloud-bigquery-storage and db_dtypes\n",
    "# Suppress warnings with a specific message\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"Your application has authenticated using end user credentials from Google Cloud SDK without a quota project.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model_name=\"gemini-2.0-flash\", temperature=0.4, top_k=30, top_p=0.3):\n",
    "    ai_client = GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=temperature,  \n",
    "            top_k=top_k,  \n",
    "            top_p=top_p\n",
    "        )\n",
    "    )\n",
    "    response_result = ai_client.generate_content(prompt)\n",
    "    return response_result.candidates[0].content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "project_name = \"snowplow-cto-office\"\n",
    "bigquery_client = bigquery.Client(project=project_name)\n",
    "product = \"smartbill\"\n",
    "#product = \"vnet_autopay\"\n",
    "#product = \"eplus\"\n",
    "dataset_id = f\"\"\"snowplow-cto-office.snowplow_{product}\"\"\"\n",
    "#full_responses_table_name = f\"\"\"snowplow-cto-office.snowplow_{product}.Vismanet_AutoPay_events_filtered_L60D\"\"\"\n",
    "\n",
    "table_names = [f\"{product}_simple_urlpath_sequences\", f\"{product}_events_custom_T60D\", f\"{product}_page_views_aggregated\", f\"{product}_session_chunks\", f\"{product}_simple_title_sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_responses_table_name = f\"\"\"{dataset_id}.{product}_session_chunks\"\"\"\n",
    "#Vismanet_AutoPay_events_filtered_L60D\n",
    "query_headers = f\"\"\"SELECT\n",
    "        column_name AS field_name,\n",
    "        data_type AS field_type,\n",
    "        description AS field_description,\n",
    "    FROM\n",
    "        `{dataset_id}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "    WHERE\n",
    "        table_name = '{product}_session_chunks';\n",
    "    \"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query_headers)\n",
    "table = query_job.result()\n",
    "\n",
    "rows = list(table)\n",
    "\n",
    "all_fields_type = {row[0]: row[1] for row in rows}\n",
    "all_fields_desc = {row[0]: row[2] for row in rows}\n",
    "all_fields_names = {row[0]: row[0] for row in rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_fields_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = {}\n",
    "for i in table_names:\n",
    "    query_tables_summary = f\"\"\"SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `{dataset_id}.INFORMATION_SCHEMA.TABLE_OPTIONS`\n",
    "    WHERE\n",
    "        option_name = 'description'\n",
    "        AND table_name = '{i}';\n",
    "    \"\"\"\n",
    "    query_job = bigquery_client.query(query_tables_summary)\n",
    "    table = query_job.result()\n",
    "    rows = list(table)\n",
    "    summary_list[f\"{i}\"] = rows[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_table(bigquery_client, prompt, keywords, expected, assumptions = None):\n",
    "    text_with_headers = f\"\"\"\n",
    "\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected}\n",
    "\n",
    "    **Assumptions about prompt:**\n",
    "    - {assumptions}\n",
    "\n",
    "    **Table schema:**\n",
    "    - Name of fields: {all_fields_names}\n",
    "    - Data type of values in the fields: {all_fields_type}\n",
    "    - Field descriptions: {all_fields_desc}\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Identify and list all relevant fields from the table schema that are useful for answering the prompt and aligning with the expected result.\n",
    "    2. Use these keywords to find the relevant fields: {keywords}.\n",
    "    3. Do not include any extraneous symbols, such as JSON formatting, brackets, or custom fields.\n",
    "    4. For each selected field, explain its relevance and how it helps to answer the prompt.\n",
    "    5. Make use of assumptions if they exist. The assumptions are correct and is incorporated into the prompt.\n",
    "\n",
    "    **Important:**\n",
    "    - If **all necessary fields** to answer the prompt are present in the schema, proceed to list the fields and their corresponding use cases: field_name, [use case]\n",
    "    - If the prompt mentions a clearly defined concept or event that is missing AND cannot be calculated or derived from the available data, return only: `False, [explanation]`\n",
    "    - Do **not** make assumptions or workarounds unless explicitly allowed.\n",
    "\n",
    "    Output format:\n",
    "    field_name1, use case\n",
    "    field_name2, use case\n",
    "    ...\n",
    "\n",
    "    Do **not** hallucinate or infer information.\n",
    "\n",
    "    \"\"\"\n",
    "    fields_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.05, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    print(fields_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_selection(bigquery_client, prompt, keywords, expected, assumptions = None):\n",
    "    print(\"Bigquery start.\")\n",
    "    #query_job = bigquery_client.query(query_headers)\n",
    "    #table = query_job.result()\n",
    "    # headers_values = []\n",
    "    #for row in table:\n",
    "    #    headers_values.append(row[:])\n",
    "    text_with_headers = f\"\"\"\n",
    "\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected}\n",
    "\n",
    "    **Assumptions about prompt:**\n",
    "    - {assumptions}\n",
    "\n",
    "    **Table schema:**\n",
    "    - Name of fields: {all_fields_names}\n",
    "    - Data type of values in the fields: {all_fields_type}\n",
    "    - Field descriptions: {all_fields_desc}\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Identify and list all relevant fields from the table schema that are useful for answering the prompt and aligning with the expected result.\n",
    "    2. Use these keywords to find the relevant fields: {keywords}.\n",
    "    3. Do not include any extraneous symbols, such as JSON formatting, brackets, or custom fields.\n",
    "    4. For each selected field, explain its relevance and how it helps to answer the prompt.\n",
    "    5. Make use of assumptions if they exist. The assumptions are correct and is incorporated into the prompt.\n",
    "\n",
    "    **Important:**\n",
    "    - If **all necessary fields** to answer the prompt are present in the schema, proceed to list the fields and their corresponding use cases: field_name, [use case]\n",
    "    - If the prompt mentions a clearly defined concept or event that is missing AND cannot be calculated or derived from the available data, return only: `False, [explanation]`\n",
    "    - Do **not** make assumptions or workarounds unless explicitly allowed.\n",
    "\n",
    "    Output format:\n",
    "    field_name1, use case\n",
    "    field_name2, use case\n",
    "    ...\n",
    "\n",
    "    Do **not** hallucinate or infer information.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Bigquery end.\")\n",
    "    fields_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.05, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    print(fields_response)\n",
    "\n",
    "\n",
    "    lines = fields_response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    var_type = []\n",
    "\n",
    "\n",
    "    for line in lines:\n",
    "        if \",\" in line:\n",
    "            first, second = line.split(\",\", 1) \n",
    "            first_part.append(first.strip())  \n",
    "            second_part.append(second.strip())  \n",
    "\n",
    "    for i in first_part:\n",
    "        var_type.append(all_fields_type[i])\n",
    "\n",
    "    fields_type = {\n",
    "        first_part[i]: {\n",
    "            'data_type': var_type[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    fields_desc = {\n",
    "        first_part[i]: {\n",
    "            'description': second_part[i],\n",
    "        }\n",
    "        for i in range(len(first_part))\n",
    "    }\n",
    "\n",
    "    return fields_type, fields_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_code(prompt, fields_type, fields_desc, strategy, keywords, expected_result, assumptions = None):\n",
    "    text_with_headers = f\"\"\"\"\n",
    "    **Prompt:** {prompt}\n",
    "\n",
    "    **Table schema:** \n",
    "    - Data types: {fields_type} \n",
    "    - Descriptions: {fields_desc} \n",
    "    - Table: {full_responses_table_name}\n",
    "\n",
    "    **Strategy:**\n",
    "    - {strategy} \n",
    "\n",
    "    **Keywords:** \n",
    "    - {keywords}\n",
    "\n",
    "    **Expected result:** \n",
    "    - {expected_result}\n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    - {assumptions}\n",
    "\n",
    "    **Constraints:** \n",
    "    - The query is sent to BigQuery. It needs to follow BigQuery syntax.\n",
    "    - Fully follow the strategy\n",
    "    - Keep query costs as low as possible\n",
    "\n",
    "    **Query Guidelines:**\n",
    "    - Select only necessary fields; avoid extra data.\n",
    "    - Show more than one entry.\n",
    "    - Use accurate column names; no transformations.\n",
    "    - Prefer partition filtering over `EXTRACT()`. Use `DATE_TRUNC(date_column, DATE_PART)` correctly (e.g., `DATE_TRUNC(session_started_date, WEEK)`), without string literals.\n",
    "    - Use approximate counts where possible.\n",
    "    - Consider clustering for better filtering.\n",
    "    - **Exclude NULL values** (`IS NOT NULL`).\n",
    "    - Make use of the assumptions. The assumptions are correct and is incorporated into the prompt.\n",
    "\n",
    "    **Final Checks:**\n",
    "    - Are only essential fields used?\n",
    "    - Does the query align with the strategy?\n",
    "    - Does the data table match keywords/expected results?\n",
    "    - **Ensure `IS NOT NULL` is used in relevant columns.**\n",
    "    - Is the query as a whole optimized for cost?\n",
    "    - Do the data types of the fields match the operations you are performing on them?\n",
    "\n",
    "    ### **Objective:**  \n",
    "    - Generate the best possible BigQuery SQL query that:  \n",
    "    1. Answers the prompt fully.  \n",
    "    2. Produces the expected result accurately.  \n",
    "    3. Follows the strategy step-by-step without deviation. Treat the strategy as a strict blueprint; implement each step exactly as described.\n",
    "\n",
    "    Use standard SQL. The query will be sent to **BigQuery**, so DO NOT INCLUDE EXPLANATIONS. Make sure the query is VALID. Do not hallucinate.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    sql_query_response = generate_response(\n",
    "        text_with_headers, \n",
    "        temperature=0.1, \n",
    "        top_k=20, \n",
    "        top_p=0.2\n",
    "    )\n",
    "\n",
    "    return sql_query_response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sql_error(prompt, keywords, expected_result, sql_code, error, fields_type, fields_desc, strategy):\n",
    "    final_prompt = f\"\"\"\n",
    "    **Prompt:**\n",
    "    - {prompt}\n",
    "\n",
    "    **Important keywords:**\n",
    "    - {keywords}\n",
    "\n",
    "    **Strategy for creating SQL code:**\n",
    "    - {strategy}\n",
    "\n",
    "    **Expected result:**\n",
    "    - {expected_result}\n",
    "    \n",
    "    ### **Original SQL Query (Faulty):**\n",
    "    {sql_code}\n",
    "\n",
    "    ### **Error Message:** \n",
    "    {error}\n",
    "\n",
    "    ### **Table Details:** \n",
    "    - Table name: {full_responses_table_name}\n",
    "    - Field data types: {fields_type}\n",
    "    - Field descriptions: {fields_desc}\n",
    "\n",
    "    ### **Table Details:** \n",
    "    Fix the SQL query to resolve the error while adhering to the provided strategy, prompt, keywords, and expected result.\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    1. Analyze the error in the error message and provide a corrected SQL query.\n",
    "    2. The output should only include the SQL code.\n",
    "    3. Follow the strategy. The strategy is correct to create the SQL code.\n",
    "    \n",
    "    ### **Output:**  \n",
    "    <fixed SQL query>\n",
    "\n",
    "    Ensure the corrected SQL follows the expected syntax and logic.\n",
    "    \"\"\"\n",
    "\n",
    "    response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.1, \n",
    "        top_k=40, \n",
    "        top_p=0.3\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    return response.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(prompt, query, expected_result, assumptions, strategy):\n",
    "    final_prompt = f\"\"\"\n",
    "    ### **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    ### **Assumptions:** \n",
    "    {assumptions}\n",
    "\n",
    "    ### **Strategy for creating SQL code:** \n",
    "    {strategy}\n",
    "\n",
    "    ### **SQL Query:** \n",
    "    {query}\n",
    "\n",
    "    ### **Expected result:** \n",
    "    {expected_result}\n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - The assumptions are verified with the user. They are equally important to the prompt and the expected result.\n",
    "\n",
    "    ### **Task:**  \n",
    "    1. Does the strategy fully align and cover all apsects of the query?\n",
    "    1. Do the strategy and the query fully answer every part of the prompt? \n",
    "    2. Do the strategy and the query fully align with the expected result?\n",
    "    3. Do the strategy and the query fully align with the assumptions?\n",
    "    \n",
    "    ### **Output format:**  \n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "    Yes/No. explanation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = generate_response(\n",
    "        final_prompt, \n",
    "        temperature=0.1, \n",
    "        top_k=30, \n",
    "        top_p=0.3\n",
    "    )\n",
    "\n",
    "    lines = response.split(\"\\n\")\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    for line in lines:\n",
    "        if \".\" in line:  # Ensure there is a comma before splitting\n",
    "            first, second = line.split(\".\", 1)  # Split only at the first comma\n",
    "            first_part.append(first.strip())  # Store the first part (column name)\n",
    "            second_part.append(second.strip())  # Store the second part (description)\n",
    "\n",
    "    check_list = []\n",
    "    for i in range(len(first_part)):\n",
    "        if first_part[i] == \"No\":\n",
    "            check_list.append(second_part[i])\n",
    "\n",
    "    return check_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_interpretation(prompt, result, strategy):\n",
    "    result_text = f\"\"\"\n",
    "    ### **Prompt:**\n",
    "    {prompt}  \n",
    "\n",
    "    ### **Strategy for getting data:**   \n",
    "    {strategy}  \n",
    "\n",
    "    ### **Data:**   \n",
    "    {result}  \n",
    "\n",
    "\n",
    "    ### **Task:**  \n",
    "    Analyze the provided dataset and generate a meaningful interpretation that answers the given prompt.  \n",
    "\n",
    "    ### **Steps:**  \n",
    "    1. **Answer the question directly.** Provide a clear, data-driven response.  \n",
    "    2. **Extract key insights.** Identify trends, anomalies, or correlations that are not immediately obvious.  \n",
    "    3. **Use external knowledge when relevant.** If applicable, explain insights using common patterns or domain knowledge.  \n",
    "    4. **Focus on the overall pattern** rather than unnecessary details unless a specific outlier is crucial.  \n",
    "    5. **State relevant assumptions.** Only include assumptions that impact the interpretation (avoid discussing column names, data types, or table structures).  \n",
    "\n",
    "    ### **Guidelines:**  \n",
    "    - **Be concise.** Prioritize clarity over lengthy explanations.  \n",
    "    - **Use a structured format.** Keep responses readable with bullet points and section headings.  \n",
    "    - **Avoid redundant details.** Don’t restate information that is already evident from the dataset.  \n",
    "    - **Ignore missing table schema details.** Focus on strategy, definitions, and calculations instead.  \n",
    "    - **Assistant with a friendly tone.** Speak to the user as if this is the data you have to asnwer the prompt. Make objective statements and discuss uncertainties when possible.  \n",
    "    - **BigQuery.** The data is extracted from BigQuery with (U.S weekday numbering convention e.g. Sunday is 1 and Monday is 2).\n",
    "    - **Use strategy for interpretation**. The strategy contains the strategy for creating SQL code to pull the data. There can be valuable information there to interpret the data.\n",
    "\n",
    "    ### **Expected Output Format:**  \n",
    "    1. **Best Answer to the Prompt** (direct response)  \n",
    "    2. **Key Insights & Trends** (summary of findings)  \n",
    "    3. **Relevant Assumptions** (only those impacting interpretation)  \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    final_answer_response = generate_response(\n",
    "        result_text, \n",
    "        temperature=0.3,  # More creativity\n",
    "        top_k=40, \n",
    "        top_p=0.6\n",
    "    )\n",
    "\n",
    "    return final_answer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(prompt, assumptions = None):\n",
    "    final_prompt = f\"\"\"\n",
    "\n",
    "    **Prompt:** \n",
    "    {prompt}\n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    {assumptions}\n",
    "\n",
    "    **Guidelines:** \n",
    "    - Extract the most important keywords from the prompt. \n",
    "    - The keywords will be given to a LLM together with the prompt so that it can better understand the prompt and what need to be answered.\n",
    "    - Choose relevant words in the prompt that need to be considered rather that conjuring up new ones. Do not include redundant keywords.\n",
    "    - Make use of assumptions if they exist. The assumptions are correct and are meant to clarify any ambiguous word or concept. You can think of them as addition to the prompt.\n",
    "\n",
    "    ** Output format:** \n",
    "    <[keyword1, keyword2, ...]>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    keywords = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2, \n",
    "            top_k=20, \n",
    "            top_p=0.5\n",
    "        )\n",
    "\n",
    "    print(keywords)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected(prompt, assumptions = None):\n",
    "    final_prompt = f\"\"\"\n",
    "\n",
    "    ### **Prompt:**   \n",
    "    {prompt} \n",
    "\n",
    "    **Assumptions about prompt:** \n",
    "    {assumptions}\n",
    "\n",
    "    **Guidelines:** \n",
    "    - What is the expected result of this prompt?. \n",
    "    - Assume user behavior data has been given.\n",
    "    - Simply state the expected result in a concise way.\n",
    "    - Make use of assumptions if they exist. The assumptions is meant to clarify any ambiguous word or concept. You can think of them as addition to the prompt. Do not change the prompt in a fundamental way.\n",
    "\n",
    "    Output format:\n",
    "    <Expected result>\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    response = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2,  # Ensures consistency\n",
    "            top_k=20, \n",
    "            top_p=0.5\n",
    "        )\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiAgent = DataQueryAgent(project_name, bigquery_client, generate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prompt = \"Where are most of our users from? \"\n",
    "#prompt = \"Which customers have the highest engagement?\"\n",
    "prompt = \"Which customers have the most sessions?\"\n",
    "prompt = \"Based on the bigger customers; what days and times is the best for performing updates, maintenance?\"\n",
    "#prompt = \"Based on the customers with the most users; what day and time is the best for performing updates, maintenance?\"\n",
    "#prompt = \"How do system outages impact user behavior? \"\n",
    "#prompt = \"How did the user behavior change between 30th december 2024, 31th december 2024, 1th january 2025 and 2nd january 2025? \"\n",
    "#prompt = \"Do performance issues correlate with a drop in activity?\"\n",
    "#prompt = \"What combination of browser and os are the worst?\"\n",
    "#prompt = \"Based on user behavior, what will the peak activity hours be tomorrow?\"\n",
    "#prompt = \"How many users used each product throughout january 2025?\"\n",
    "#prompt = \"How does app performance affect user engagement and retention?\"\n",
    "#prompt = \"Which devices or OS versions are experiencing the worst performance (slower load times, etc)? And are there any ptoential reason for it? Find sinsights by comparing with other metrics\"\n",
    "#prompt = \"Can you see a pattern if you compare Network Latency, Page Load Fails, Page Loading Time and Device and browsers?\"\n",
    "#prompt = \"for all windows user, what browser should we recomend between Edge or Chrome\"\n",
    "#prompt = \"Can you calculate the DAU/WAU and WAU/MAU stickiness for the products for all months in 2024?\"\n",
    "prompt = \"Can you calculate the WAU/MAU stickiness for the products for all weeks in 2024?\"\n",
    "#prompt = \"Calculate the weekly stickiness (defined as the percentage of weekly active users who used the product in the previous week) for each product in our catalog for every week of the year 2024. Provide the output as a table with the following columns: Week Number (2024), Product name, and Weekly Stickiness (%)?\"\n",
    "#prompt = \"Are there any specific customers that have huge page load times?\"\n",
    "#prompt = \"Network latency & slow load times observed during peak hours\"\n",
    "#prompt = \"Most common drop-off points\"\n",
    "\n",
    "#Stickiness\n",
    "#USers from vestlandfylke has ued teh solution\n",
    "\n",
    "response = aiAgent.process_prompt(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"text-embedding-004\"\n",
    "model = TextEmbeddingModel.from_pretrained(model)\n",
    "\n",
    "input_texts = [\n",
    "    TextEmbeddingInput(text=\"What is Vertex AI?\"),\n",
    "    TextEmbeddingInput(text=\"Machine learning in Google Cloud\"),\n",
    "]\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = model.get_embeddings(input_texts)\n",
    "\n",
    "# Display results\n",
    "for text, embedding in zip(input_texts, embeddings):\n",
    "    print(f\"Text: {text.text}\")\n",
    "    print(f\"Embedding (first 5 values): {embedding.values[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQueryAgent:\n",
    "    \"\"\"\n",
    "    A class responsible for processing user prompts to generate and validate SQL queries \n",
    "    using BigQuery, incorporating user clarifications and query refinement.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_id: str, bigquery_client, generate_response_fn):\n",
    "        \"\"\"Initializes the DataQueryAgent with the BigQuery client and response generator.\"\"\"\n",
    "        self.client = bigquery_client\n",
    "        self.project_id = project_id\n",
    "        self.generate_response = generate_response_fn\n",
    "    \n",
    "    def process_prompt(self, user_input):\n",
    "        \"\"\"Processes user input to generate, validate, and execute an SQL query.\"\"\"\n",
    "        expected_result = expected(user_input)\n",
    "        keywords = extract_keywords(user_input)\n",
    "        fields_type, fields_desc = field_selection(self.client, user_input, keywords, expected_result)\n",
    "        assumptions = self.make_assumptions(user_input, fields_type, fields_desc, keywords, expected_result)\n",
    "        while True:\n",
    "            user_clarifications = input(self.clarify_assumptions(assumptions))\n",
    "            if (user_clarifications == \"\" or user_clarifications == \"yes\" or user_clarifications == \"y\"):\n",
    "                break\n",
    "            assumptions = self.interpret_clarification(user_input, assumptions, user_clarifications)\n",
    "        print(assumptions)\n",
    "        expected_result = expected(user_input, assumptions)\n",
    "        keywords = extract_keywords(user_input, assumptions)\n",
    "        fields_type, fields_desc = field_selection(self.client, user_input, keywords, expected_result, assumptions)\n",
    "\n",
    "        # Query generation and validation loop\n",
    "        query_attempts = 0\n",
    "        while query_attempts < 3:\n",
    "            strategy = self.aggregation_strategy(user_input, fields_type, fields_desc, keywords, expected_result, assumptions)\n",
    "            sql_code = create_sql_code(user_input, fields_type, fields_desc, strategy, keywords, expected_result, assumptions)\n",
    "            print(sql_code)\n",
    "            validation_errors = verify(user_input, sql_code, expected_result, assumptions, strategy)\n",
    "            print(validation_errors)\n",
    "            \n",
    "            if not validation_errors:\n",
    "                break  # Exit loop if query is valid\n",
    "            query_attempts += 1\n",
    "        else:\n",
    "            return \"Failed to generate a valid SQL query after 3 attempts.\"\n",
    "        \n",
    "        # Validate SQL using BigQuery dry run\n",
    "        valid_result = self.validate_sql_query(user_input, keywords, expected_result, sql_code, fields_type, fields_desc, strategy)\n",
    "        if not valid_result[0]:\n",
    "            return \"An error occurred. Please try again.\"\n",
    "        \n",
    "        # Execute query and return results\n",
    "        result = valid_result[1].map(lambda x: \"Missing Data\" if x == \"\" else x)\n",
    "        result = result.map(lambda x: \"Missing Data\" if x == \"None\" else x)\n",
    "\n",
    "        interpretation = result_interpretation(user_input, result, strategy)\n",
    "        print(result)\n",
    "        return interpretation\n",
    "    \n",
    "    def validate_sql_query(self, user_input, keywords, expected, sql_code, fields_type, fields_desc, strategy):\n",
    "        \"\"\"Performs a dry run of the SQL query to check validity.\"\"\"\n",
    "        job_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                query_job = self.client.query(sql_code, job_config=job_config)\n",
    "                query_job.result()\n",
    "                print(f\"Query is valid. Estimated processing: {query_job.total_bytes_processed / 1e9:.2f} GB.\")\n",
    "                result = self.client.query(sql_code).to_dataframe()\n",
    "                return True, result\n",
    "            except Exception as e:\n",
    "                print(f\"Query validation failed (Attempt {attempt + 1}/3): {e}\")\n",
    "                sql_code = correct_sql_error(user_input, keywords, expected, sql_code, e, fields_type, fields_desc, strategy)\n",
    "        return False, False\n",
    "    \n",
    "    def interpret_clarification(self, prompt, assumptions, user_clarifications):\n",
    "        \"\"\"Refines assumptions based on user clarifications.\"\"\"\n",
    "        clarification_prompt = f\"\"\"\n",
    "        ### **Initial Prompt:** {prompt}\n",
    "        ### **Current Assumptions:** {assumptions}\n",
    "        ### **User Clarifications:** {user_clarifications}\n",
    "        \n",
    "        ### **Task:**\n",
    "        - Update current assumptions based on user clarifications.\n",
    "        - If no new information is provided, simply return the current assumptions.\n",
    "        \n",
    "        ### **Output Format:**\n",
    "        1. ...\n",
    "        2. ...\n",
    "        ...\n",
    "        \"\"\"\n",
    "        return self.generate_response(clarification_prompt, temperature=0.2, top_k=40, top_p=0.5)\n",
    "    \n",
    "    def clarify_assumptions(self, assumptions):\n",
    "        \"\"\"Generates a message to ask the user for assumption clarifications.\"\"\"\n",
    "        return f\"Are the following assumptions correct?\\n\\n{assumptions}\"\n",
    "    \n",
    "    def make_assumptions(self, prompt, fields_type, fields_desc, keywords, expected_result):\n",
    "        \"\"\"Determines initial SQL strategy assumptions based on user input.\"\"\"\n",
    "        strategy_prompt = f\"\"\"\n",
    "        ### **Prompt:** {prompt}\n",
    "        ### **Keywords:** {keywords}\n",
    "        ### **Expected Result:** {expected_result}\n",
    "        ### **Table Info:**\n",
    "        - Fields Type: {fields_type}\n",
    "        - Fields Description: {fields_desc}\n",
    "        \n",
    "        ### **Constraints:**\n",
    "        - Use only given fields.\n",
    "        - No external data or assumptions beyond the provided fields.\n",
    "        \n",
    "        ### **Task:**\n",
    "        - Propose short, reasonable, and user-friendly assumptions to resolve these ambiguities, leveraging the table info implicitly.\n",
    "        - Base assumptions on the most likely intent of the prompt, keywords, and expected result, informed by available data patterns.\n",
    "        - Keep assumptions simple and verifiable by the user, who lacks table schema knowledge.\n",
    "        - Make yours assumptions as short and punctual as possible.\n",
    "        - Do NOT generate SQL code.\n",
    "        \n",
    "        ### **Output Format:**\n",
    "        1. ...\n",
    "        2. ...\n",
    "        \"\"\"\n",
    "        return self.generate_response(strategy_prompt, temperature=0.1, top_k=20, top_p=0.3)\n",
    "    \n",
    "    def aggregation_strategy(self, prompt, fields_type, fields_desc, keywords, expected_result, assumptions):\n",
    "        \n",
    "        final_prompt = f\"\"\"Craft a precise SQL query strategy to address the prompt, ensuring alignment with the expected results and keywords.\n",
    "\n",
    "        ### **Prompt:**  \n",
    "        - {prompt}\n",
    "\n",
    "        ### **Keywords:**  \n",
    "        - {keywords}  \n",
    "\n",
    "        ### **Expected Result:**  \n",
    "        - {expected_result}  \n",
    "\n",
    "        ### **Table Details:**  \n",
    "        - Table name: {full_responses_table_name}  \n",
    "        - Field data types: {fields_type}  \n",
    "        - Field descriptions: {fields_desc}  \n",
    "\n",
    "        ### **Assumptions:**  \n",
    "        - {assumptions}  \n",
    "\n",
    "        ### **Constraints:**  \n",
    "        - Use only the fields in the specified table—no external data or tables.  \n",
    "        - Base the strategy solely on the given prompt, keywords, expected result, and table details.  \n",
    "\n",
    "        ### **Guidelines:**  \n",
    "        1. **Analyze the Prompt:** Break down the prompt to identify the core question or insight (e.g., trends, counts, comparisons). Use keywords to pinpoint critical elements.  \n",
    "        2. **Map Fields to Prompt:** Select relevant fields from the table that directly address the prompt and expected result. Justify each field’s inclusion based on its description and data type.  \n",
    "        3. **Determine Analysis Type:** Decide if aggregation (e.g., SUM, COUNT, AVG) or per-record analysis is needed, based on the expected result. Avoid unnecessary complexity.  \n",
    "        4. **Address Challenges:** Identify potential issues (e.g., ambiguous terms, data limitations) and propose concise solutions using the given fields and assumptions.  \n",
    "        5. **Incorporate Assumptions:** Apply the assumptions as foundational rules to shape the query logic.  \n",
    "\n",
    "        ### **SQL Strategy Requirements:**  \n",
    "        - Suggest specific SQL operations (e.g., SELECT, WHERE, GROUP BY) tailored to the prompt and expected result.  \n",
    "        - Use filters, joins (within the table), or calculations only if supported by the fields and prompt.  \n",
    "        - Avoid speculative insights beyond the data in the table.  \n",
    "        - Present a clear, step-by-step plan using SQL concepts—do not write the full query.  \n",
    "\n",
    "        ### **Output Format:**  \n",
    "        - **SQL Strategy:**  \n",
    "        - Step 1: (\"Purpose\" - SQL action, e.g., \"Filter data\" - Use WHERE clause with condition X)  \n",
    "        - Step 2: (\"Purpose\" - SQL action, e.g., \"Aggregate results\" - Use COUNT on field Y)  \n",
    "        - (Continue as needed)  \n",
    "        - **Verification:** Confirm the strategy produces a result matching the expected result and reflects the keywords.  \n",
    "\n",
    "        ### **Notes:**  \n",
    "        - Keep the strategy concise and focused—no fluff or extraneous steps.  \n",
    "        - Treat keywords as a guide to emphasize the prompt’s priorities.  \n",
    "        - Do not generate executable SQL code—focus on the conceptual approach.  \n",
    "        \"\"\"\n",
    "\n",
    "        sql_strategy_response = generate_response(\n",
    "            final_prompt, \n",
    "            temperature=0.2, \n",
    "            top_k=40, \n",
    "            top_p=0.5\n",
    "        )\n",
    "        print(sql_strategy_response)\n",
    "\n",
    "        return sql_strategy_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
